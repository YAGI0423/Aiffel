{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cloudy-footage",
   "metadata": {},
   "source": [
    "# 어텐션을 활용한 추상적 요약 모델 생성 및 평가 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-characteristic",
   "metadata": {},
   "source": [
    "#### 초록\n",
    "***\n",
    "<span style=\"font-size:11pt; line-height:1.8;\">\n",
    "    &nbsp; &nbsp; seq2seq 모델과 어텐션을 활용하여 문장 요약 모델을 생성하고 이를 추출적 요약과 비교하여 평가를 실시 하였다. 데이터는 뉴스 기사에 대한 원문과 제목을 이용하였으며, 데이터 분석과 데이터 전처리 과정을 진행하였다. 데이터 전처리 과정에서는 텍스트 정규화, 불용어 제거, html tag 제거, 패딩 추가 등의 작업을 시행하고 해당 데이터를 학습 데이터와 테스트 데이터로 분리하였다. 모델 평가에서는 임의의 다섯 문장에 대한 모델의 요약문과 추출적 요약의 요약문을 비교하였으며, 평가 지표로 문법이 틀린 개수인 '문법 오류 정도'와 동사와 명사 일치 개수인 '단어 일치 정도'를 사용하였으며, 그 결과 모델의 경우 평균 문법 오류 정도는 0.2였다. 단어 일치 정도는 1.8 이었으며, 추출적 요약의 평균 문법 오류 정도는 0이었으며, 단어 일치 정도는 3.6이었다. 추출적 요약의 경우가 더 잘 요약한 것이라 할 수 있지만, 추출적 요약의 경우 전혀 다른 문장을 제시하거나 하는 문제가 있고 추상적 요약의 경우 문장의 의미를 잘 요약한 점과 원문으로부터 새로운 문장을 생성한다는 점에서 개선의 여지가 있다고 할 수 있다.\n",
    "</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-greece",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1. 서론\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 본 예제에서는 어텐션을 활용하여 자연어 문장을 요약하는 추상적 요약 모델을 생성하고 이를 '추출적 요약'과 비교하여 평가하고자 합니다. '추상적 요약'은 문장으로부터 새로운 문장을 생성하여 원문을 요약하는 것입니다. '추출적 요약'은 원문의 문장을 그대로 이용하는 것입니다. 예제는 '뉴스 기사 데이터'를 데이터셋으로 이용 합니다. 예제 진행은 크게 '데이터 분석', '데이터 전처리', '추상적 모델 생성 및 학습', '추출적 요약과 비교한 모델 평가' 순으로 진행 됩니다.\n",
    "</span><br><br>\n",
    "\n",
    "\n",
    "> _1. 데이터 분석_\n",
    ">\n",
    "> _2. 데이터 전처리_\n",
    ">\n",
    "> _3. 추상적 모델 생성 및 학습_\n",
    ">\n",
    "> _4. 추출적 요약과 비교한 모델 평가_\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-independence",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2. 데이터 분석\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 데이터 분석 단계에서는 데이터 레코드 수, 어트리뷰트, 데이터 자료형 등의 기본적인 정보를 살펴 본 후, 좀 더 자세한 분석을 위해 '중복 데이터 제거', '텍스트 정규화 및 불용어 제거'와 같은 데이터 정제를 진행 합니다. 이후, 데이터의 결측 값 여부와 문장의 길이에 대한 통계를 살펴보고 최적의 문장 길이를 확보하고자 합니다.\n",
    "</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-dancing",
   "metadata": {},
   "source": [
    "#### 필요 라이브러리 호출\n",
    "***\n",
    "+ 예제 진행에 필요한 라이브러리를 호출 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dynamic-variance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle   #plk 파일 load\n",
    "import numpy as np   #행렬 연산\n",
    "import pandas as pd   #csv 파일 로드\n",
    "import matplotlib.pyplot as plt   #시각화\n",
    "\n",
    "\n",
    "import requests   #추출적 요약\n",
    "from summa.summarizer import summarize   #추출적 요약2\n",
    "\n",
    "import re   #정규식\n",
    "import nltk   #자연어\n",
    "nltk.download('stopwords')   #불용어\n",
    "from nltk.corpus import stopwords   #불용어\n",
    "from bs4 import BeautifulSoup   #마크업 용어 제거\n",
    "\n",
    "\n",
    "import time   #멀티프로세싱 작업 소요 시간 체크\n",
    "import multiprocessing as mp   #Multi Processing\n",
    "from multiprocessing import Pool   #멀티프로세싱\n",
    "from functools import partial   #map 함수 여러 인자\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Model   #모델\n",
    "from attention import AttentionLayer   #어텐션\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer   #토크나이저\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences   #패딩추가\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint   #콜백함수\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate   #모델 레이어"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suburban-coffee",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 2.1. 데이터 기본 정보 분석\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 데이터의 기본 정보에 대해 알아봅니다. 데이터셋은 요약문(`headlins`)와 원문(`text`) 속성으로 구성되어 있으며, 영문 문장에 해당 합니다. 결측치는 없었으며, 총 레코드 수는 98,401개 입니다. 원문과 요약문의 중복을 제외한 데이터는 각각 98,360개, 98,280개 입니다.\n",
    "</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identified-remainder",
   "metadata": {},
   "source": [
    "#### 데이터 기본 정보\n",
    "***\n",
    "+ `headlines`, `text` 속성으로 구성되며, `headlines`는 '요약문', `text`는 '원문'으로 두 속성의 데이터 모두 자연어에 해당 합니다.\n",
    "\n",
    "\n",
    "+ 두 속성의 데이터 모두 `NULL` 값은 없습니다.\n",
    "\n",
    "\n",
    "+ 데이터 레코드는 총 98,401개 입니다.\n",
    "\n",
    "\n",
    "+ `headlines` 고유 값은 총 98,280개, `text` 고유 값은 총 98,360개 입니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "statutory-petite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "<DATA INFO>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 98401 entries, 0 to 98400\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   headlines  98401 non-null  object\n",
      " 1   text       98401 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.5+ MB\n",
      "None\n",
      "************************************************************\n",
      "\n",
      "\n",
      "************************************************************\n",
      "<DATA DESCRIBE>\n",
      "                                                headlines  \\\n",
      "count                                               98401   \n",
      "unique                                              98280   \n",
      "top     Why is England-Australia Test series called 'T...   \n",
      "freq                                                    3   \n",
      "\n",
      "                                                     text  \n",
      "count                                               98401  \n",
      "unique                                              98360  \n",
      "top     Berger Paints has launched Berger Express Pain...  \n",
      "freq                                                    2  \n",
      "************************************************************\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
       "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
       "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
       "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
       "      <td>Speaking about the sexual harassment allegatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upGrad learner switches to career in ML & Al w...   \n",
       "1  Delhi techie wins free food from Swiggy for on...   \n",
       "2  New Zealand end Rohit Sharma-led India's 12-ma...   \n",
       "3  Aegon life iTerm insurance plan helps customer...   \n",
       "4  Have known Hirani for yrs, what if MeToo claim...   \n",
       "\n",
       "                                                text  \n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's...  \n",
       "1  Kunal Shah's credit card bill payment platform...  \n",
       "2  New Zealand defeated India by 8 wickets in the...  \n",
       "3  With Aegon Life iTerm Insurance plan, customer...  \n",
       "4  Speaking about the sexual harassment allegatio...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./dataset/news_summary_more.csv', encoding='iso-8859-1')   #csv 파일 불러오기\n",
    "\n",
    "\n",
    "#출력부============================\n",
    "print(\"*\" * 60)\n",
    "print(\"<DATA INFO>\")\n",
    "print(data.info())\n",
    "print(\"*\" * 60)\n",
    "\n",
    "print(\"\\n\\n\" + \"*\" * 60)\n",
    "print(\"<DATA DESCRIBE>\")\n",
    "print(data.describe())\n",
    "print(\"*\" * 60)\n",
    "\n",
    "data.head(5)\n",
    "#End==============================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-radical",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 데이터 샘플 확인\n",
    "***\n",
    "+ 요약문과 원문 샘플을 확인 합니다.\n",
    "\n",
    "<br>\n",
    "\n",
    "> __upGrad 학습자가 90% 급여 인상과 함께 ML 및 Al에서 경력으로 전환__\n",
    "\n",
    "> 기계 학습 및 인공 지능 분야의 upGrad 및 IIIT-B PG 프로그램 졸업생인 Saurav Kant는 거의 5년 간의 업무 경험을 가진 Infosys의 수석 시스템 엔지니어였습니다. 이 프로그램과 upGrad의 360도 경력 지원은 그가 90%의 급여 인상과 함께 Tech Mahindra의 데이터 과학자로 전환하는 데 도움이 되었습니다. upGrad의 온라인 파워 러닝은 30만 이상의 경력을 쌓았습니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "failing-opportunity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "<HEADLINE SAMPLE>\n",
      "upGrad learner switches to career in ML & Al with 90% salary hike\n",
      "************************************************************\n",
      "\n",
      "\n",
      "************************************************************\n",
      "<TEXT SAMPLE>\n",
      "Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike. upGrad's Online Power Learning has powered 3 lakh+ careers.\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "#출력부============================\n",
    "print(\"*\" * 60)\n",
    "print(\"<HEADLINE SAMPLE>\")\n",
    "print(data[\"headlines\"][0])\n",
    "print(\"*\" * 60)\n",
    "\n",
    "print(\"\\n\\n\" + \"*\" * 60)\n",
    "print(\"<TEXT SAMPLE>\")\n",
    "print(data[\"text\"][0])\n",
    "print(\"*\" * 60)\n",
    "#End==============================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-incidence",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 2.2. 데이터 정제\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 조금더 자세한 분석을 위해 데이터 정제를 실시 합니다. 데이터 정제는 '원문 중복 데이터 제외', '텍스트 정규화', '불용어 제외', 'html 태그 제거' 등의 처리를 거칩니다. 중복 데이터 제거를 원문에 한해 시행하는 이유는 요약문은 중복되어도 원문이 다를 수 있기 때문에,\n",
    "원문을 기준으로 중복 데이터를 제거 합니다.\n",
    "</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sporting-antibody",
   "metadata": {},
   "source": [
    "#### 원문 중복 데이터 제외\n",
    "***\n",
    "+ '요약문'이 중복 되어도 '원문'은 다를 수가 있습니다.\n",
    "\n",
    "\n",
    "+ 하지만 '원문'이 중복된 것은 같은 데이터가 두 개 이상 있는 것이니 제외 합니다.\n",
    "\n",
    "\n",
    "+ `title`을 기준으로 중복 데이터를 제외하고 총 98,360개의 레코드를 획득 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "convinced-closer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "<DATA DESCRIBE>\n",
      "                                          headlines  \\\n",
      "count                                         98360   \n",
      "unique                                        98262   \n",
      "top     Don Bradman once scored 100 runs in 3 overs   \n",
      "freq                                              3   \n",
      "\n",
      "                                                     text  \n",
      "count                                               98360  \n",
      "unique                                              98360  \n",
      "top     The UN has asked the UK to suspend work at the...  \n",
      "freq                                                    1  \n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "data.drop_duplicates(subset = ['text'], inplace=True)   #'text' 기준 중복 데이터 제거\n",
    "\n",
    "\n",
    "#출력부============================\n",
    "print(\"*\" * 60)\n",
    "print(\"<DATA DESCRIBE>\")\n",
    "print(data.describe())\n",
    "print(\"*\" * 60)\n",
    "#End==============================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-chess",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 텍스트 정규화\n",
    "***\n",
    "+ `it will`, `it'll` 또는 `is not`, `isn't`처럼 동일한 표현을 통합하여 처리 합니다.\n",
    "\n",
    "\n",
    "+ 텍스트 정규화를 위한 사전을 'pickl' 파일로 저장하여, 필요 시에 불러와 사용 합니다.\n",
    "\n",
    "\n",
    "+ 텍스트 정규화 대상 단어는 총 120개 입니다.\n",
    "\n",
    "\n",
    "+ 텍스트 정규화 사전 데이터 중 5개를 출력 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "charming-minute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "KEY: ain't\tVALUE: is not\n",
      "KEY: aren't\tVALUE: are not\n",
      "KEY: can't\tVALUE: cannot\n",
      "KEY: 'cause\tVALUE: because\n",
      "KEY: could've\tVALUE: could have\n",
      "************************************************************\n",
      "contractions num: 120\n"
     ]
    }
   ],
   "source": [
    "#텍스트 정규화 사전 불러오기=============\n",
    "with open('./dataset/contractions.pkl', 'rb') as f:\n",
    "    contractions = pickle.load(f)\n",
    "#End=====================================\n",
    "\n",
    "\n",
    "#출력부============================\n",
    "print(\"*\" * 60)\n",
    "for key, value in contractions.items():\n",
    "    print(\"KEY: {0}\\tVALUE: {1}\".format(key, value))\n",
    "    if key == \"could've\": break;\n",
    "print(\"*\" * 60)\n",
    "\n",
    "print(\"contractions num:\", len(contractions))\n",
    "#End==============================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-trailer",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 불용어 처리\n",
    "***\n",
    "+ 자주 쓰이지만 자연어 처리에 영향을 미치지 않는 '불용어'를 제외 합니다.\n",
    "\n",
    "\n",
    "+ 불용어는 총 179개 입니다.\n",
    "\n",
    "\n",
    "+ NLTK에서 제공하는 불용어 리스트 중 5개의 샘플을 출력 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "personalized-tampa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "i\n",
      "me\n",
      "my\n",
      "myself\n",
      "we\n",
      "our\n",
      "************************************************************\n",
      "stopwords num: 179\n"
     ]
    }
   ],
   "source": [
    "#출력부============================\n",
    "print(\"*\" * 60)\n",
    "for idx, word in enumerate(stopwords.words(\"english\")):\n",
    "    print(word)\n",
    "    if idx == 5: break;\n",
    "print(\"*\" * 60)\n",
    "\n",
    "print(\"stopwords num:\", len(stopwords.words('english')))\n",
    "#End==============================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-marble",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 데이터 정제 함수 생성\n",
    "***\n",
    "+ 전체 문장 소문자로 변경, html 태그 제거, 특수문자 제거 등의 정제 함수를 생성 합니다.\n",
    "\n",
    "\n",
    "+ '원문'에 대해서만 불용어를 제거하고 '요약문'에서는 불용어를 포함하기 위해 `remove_stopwords`를 매개변수로하여 불용어 제외 여부를 선택 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "digital-cleaners",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "You need cooling, Baby I'm not fooling.\n",
      "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓\n",
      "['need cooling baby fooling']\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리 함수===================\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\", sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    if remove_stopwords:   #불용어 제거 여부\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    else:   #불용어 미제거 (Summary)\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens\n",
    "#End===================================\n",
    "\n",
    "\n",
    "#여러 문장에 대한 전처리===============\n",
    "def appendTexts(sentences, remove_stopwords):\n",
    "    texts = []\n",
    "    for s in sentences:\n",
    "        texts += preprocess_sentence(s, remove_stopwords),\n",
    "    return texts\n",
    "#End===================================\n",
    "\n",
    "\n",
    "#출력부================================\n",
    "text = \"You need cooling, Baby I'm not fooling.\"   #Whole Lotta Love - Led Zeppelin / 1969\n",
    "print(\"*\" * 60)\n",
    "print(text)\n",
    "print(\"↓\" * 20)\n",
    "print(appendTexts([text], True))\n",
    "print(\"*\" * 60)\n",
    "#End=================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-leeds",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 멀티프로세싱 데이터 정제 함수 생성\n",
    "***\n",
    "+ 다량의 데이터를 정제 해야하므로 멀티프로세싱을 이용하여 시간을 단축 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "virgin-appraisal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data, remove_stopwords=True):\n",
    "    start_time = time.time()\n",
    "    num_cores = mp.cpu_count()  # 컴퓨터의 코어 수\n",
    "\n",
    "    text_data_split = np.array_split(data, num_cores)  # 코어 수만큼 데이터를 배분하여 병렬 처리\n",
    "    pool = Pool(num_cores)\n",
    "\n",
    "    processed_data = np.concatenate(   # 각자 작업한 데이터 합치기\n",
    "        pool.map(\n",
    "            partial(appendTexts, remove_stopwords=remove_stopwords),\n",
    "            text_data_split\n",
    "        )\n",
    "    )  \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    print(\"Data cleaning: \", round(time.time() - start_time, 2), \" seconds\")\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-apple",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 데이터 정제 실시\n",
    "***\n",
    "+ 앞서 생성한 함수를 바탕으로 데이터 정제를 실시 합니다.\n",
    "\n",
    "\n",
    "+ 원문 즉, `text` 데이터는 불용어를 제거하고, 요약문인 `headlines` 데이터는 불용어를 제거하지 않습니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "stylish-moses",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Start `text` data cleaning...\n",
      "Data cleaning:  415.13  seconds\n",
      "Done `text` data cleaning...\n",
      "**************************************************\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Start `summary` data cleaning...\n",
      "Data cleaning:  12.73  seconds\n",
      "Done `summary` data cleaning...\n",
      "**************************************************\n",
      "\n",
      "\n",
      "************************************************************\n",
      "<HEADLINE SAMPLE>\n",
      "saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers\n",
      "************************************************************\n",
      "\n",
      "\n",
      "************************************************************\n",
      "<TEXT SAMPLE>\n",
      "upgrad learner switches to career in ml al with salary hike\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "#데이터 정제 실시==================\n",
    "print(\"*\" * 50)\n",
    "print(\"Start `text` data cleaning...\")\n",
    "clean_text = preprocess_data(data['text'])\n",
    "print(\"Done `text` data cleaning...\")\n",
    "print(\"*\" * 50)\n",
    "\n",
    "print(\"\\n\\n\" + \"*\" * 50)\n",
    "print(\"Start `summary` data cleaning...\")\n",
    "clean_summary = preprocess_data(data['headlines'], remove_stopwords=False)\n",
    "print(\"Done `summary` data cleaning...\")\n",
    "print(\"*\" * 50)\n",
    "#End===============================\n",
    "\n",
    "#정제 데이터로 대체================\n",
    "data['text'] = clean_text\n",
    "data['headlines'] = clean_summary\n",
    "#End===============================\n",
    "\n",
    "\n",
    "#출력부============================\n",
    "print(\"\\n\\n\" + \"*\" * 60)\n",
    "print(\"<HEADLINE SAMPLE>\")\n",
    "print(clean_text[0])\n",
    "print(\"*\" * 60)\n",
    "\n",
    "print(\"\\n\\n\" + \"*\" * 60)\n",
    "print(\"<TEXT SAMPLE>\")\n",
    "print(clean_summary[0])\n",
    "print(\"*\" * 60)\n",
    "#End==============================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-values",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 2.3. 정제 후 데이터 분석\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 조금 더 자세한 데이터 분석을 실시 합니다. 데이터 정제를 실시 하였기 때문에 결측지를 다시 확인 한 결과, 결측치는 발견되지 않았습니다. 이후의 모델이 입력 받을 문장의 길이를 설정하기 위해 최적의 문장 길이를 판단하기 위해, 데이터셋의 문장 길이를 분석하였습니다. 원문(text)의 경우 최대 60개의 단어로 구성된 문장이 존재하며, 평균 35개의 단어로 문장이 이루어져 있음을 확인하였습니다. 요약문(headlines)의 경우 최대 16개의 단어로 구성된 문장이 존재하며 평균 9개의 단어로 문장이 이루어져 있음을 확인하였습니다. 또한, 원문의 경우 40개 이하의 단어로 구성된 문장이 약 92.4%이며, 요약문의 경우 11개 이하의 단어로 구성된 문장이 약 94.5%인 것을 확인하였습니다.\n",
    "</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-belief",
   "metadata": {},
   "source": [
    "#### NULL 값 확인\n",
    "***\n",
    "+ 데이터 정제 후 `NULL` 값을 확인 합니다.\n",
    "\n",
    "+ `text`, `headlines` 모두 `NULL` 값이 존재하지 않습니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "blind-consideration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "<DATA INFO>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 98360 entries, 0 to 98400\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   headlines  98360 non-null  object\n",
      " 1   text       98360 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.3+ MB\n",
      "None\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "data.replace('', np.nan, inplace=True)   #빈 값을 Null 값으로 변환\n",
    "\n",
    "\n",
    "#출력부============================\n",
    "print(\"*\" * 60)\n",
    "print(\"<DATA INFO>\")\n",
    "print(data.info())\n",
    "print(\"*\" * 60)\n",
    "#End=============================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-socket",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 문장 길이 분석\n",
    "***\n",
    "+ 원문 즉, `text`의 경우 하나의 단어로 구성된 데이터가 존재 하며, 최대 60개의 단어로 구성된 문장이 존재하고 평균 약 35개의 단어로 문장이 이루어져 있습니다.\n",
    "\n",
    "\n",
    "+ 요약문 즉, `headlines`의 경우 하나의 단어로 구성된 데이터가 존재 하며, 최대 16개의 단어로 구성된 문장이 존재하고 평균 약 9개의 단어로 문장이 이루어져 있습니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "forty-yield",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "text min len: 1\n",
      "text max len: 60\n",
      "text avg len: 35.09968483123221\n",
      "\n",
      "headline min len: 1\n",
      "headline max len: 16\n",
      "headline avg len: 9.299532330215534\n",
      "************************************************************\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_len = [len(s.split()) for s in data['text']]   #원문에 대한 문장 길이\n",
    "summary_len = [len(s.split()) for s in data['headlines']]   #요약문에 대한 문장 길이\n",
    "\n",
    "\n",
    "#출력부============================\n",
    "print(\"*\" * 60)\n",
    "print('text min len: {}'.format(np.min(text_len)))\n",
    "print('text max len: {}'.format(np.max(text_len)))\n",
    "print('text avg len: {}'.format(np.mean(text_len)))\n",
    "\n",
    "print('\\nheadline min len: {}'.format(np.min(summary_len)))\n",
    "print('headline max len: {}'.format(np.max(summary_len)))\n",
    "print('headline avg len: {}'.format(np.mean(summary_len)))\n",
    "print(\"*\" * 60)\n",
    "#End==============================\n",
    "\n",
    "\n",
    "#시각화===========================\n",
    "plt.figure(figsize=(7, 10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.boxplot(summary_len)\n",
    "plt.title('headline')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('text')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.subplots_adjust(right=1.8)\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.hist(summary_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.show()\n",
    "#End=============================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-literature",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 최적 문장 길이 확보하기\n",
    "***\n",
    "+ 원문의 경우 40개 이하의 단어로 구성된 문장이 약 92.4%를 이룹니다.\n",
    "\n",
    "\n",
    "+ 요약문의 경우 11개 이하의 단어로 구성된 문장이 약 94.5%를 이룹니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fiscal-relations",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "40 len text record: 0.924\n",
      "11 len headlines record: 0.945\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "#문장 길이에 따른 데이터 비율 확인 함수=============\n",
    "def below_threshold_len(max_len, nested_list):\n",
    "    cnt = 0\n",
    "    for s in nested_list:\n",
    "        if(len(s.split()) <= max_len):\n",
    "            cnt = cnt + 1\n",
    "    return round(cnt/ len(nested_list), 3)\n",
    "#End================================================\n",
    "\n",
    "\n",
    "#출력부============================\n",
    "text_max_len, summary_max_len = 40, 11\n",
    "\n",
    "print(\"*\" * 60)\n",
    "print(\"40 len text record:\", below_threshold_len(text_max_len, data[\"text\"]))\n",
    "print(\"11 len headlines record:\", below_threshold_len(summary_max_len, data[\"headlines\"]))\n",
    "print(\"*\" * 60)\n",
    "#End=============================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-cooper",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 3. 데이터 전처리\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 데이터 전처리 단계에서는 앞서 실시한 분석을 바탕으로 문장 길이에 따른 데이터를 제외 하거나 단어 사전을 생성하여 문장을 토큰화 하는 등의 학습 데이터로 사용할 수 있게 데이터를 수정합니다. 특히, 문장의 단어 수를 데이터의 약 90%의 비중을 차지하는 원문은 40개, 요약문은 11개 이하의 단어로 구성된 문장만 확보 합니다. 최종적으로 학습 데이터 68,675개, 테스트 데이터 17,168개를 확보 하였습니다.\n",
    "</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chinese-thomas",
   "metadata": {},
   "source": [
    "### 3.1. 데이터 전처리를 통한 학습 데이터 생성\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 앞서 분석 단계에서 획득한 각 데이터에 대한 문장 길이를 바탕으로 원문은 40개 단어 초과, 요약문은 11개 단어 초과 문장을 제외 합니다. 이후, 모델이 문장을 예측 할 수 있도록 시작과 종료 토큰을 추가하여 줍니다. 또한, 데이터를 학습 데이터와 테스트 데이터로 분리하여 줍니다. 최종적으로 학습 데이터 68,675개, 테스트 데이터 17,168개를 획득 하였습니다.\n",
    "</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-stopping",
   "metadata": {},
   "source": [
    "#### 문장길이에 따른 데이터 제외\n",
    "***\n",
    "+ 앞서 획득한 원문과 요약문에 대한 문장 길이를 바탕으로 해당 문장 길이보다 긴 문장은 제외 합니다.\n",
    "\n",
    "\n",
    "+ 원문(`text`)은 40개 단어 초과, 요약문(`headlines`)은 11개 단어 초과 문장을 제외 합니다.\n",
    "\n",
    "\n",
    "+ 총 85,843개의 레코드를 획득 하였습니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "productive-flexibility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "<DATA INFO>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 85843 entries, 0 to 98400\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   headlines  85843 non-null  object\n",
      " 1   text       85843 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.0+ MB\n",
      "None\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "data = data[data['text'].apply(lambda x: len(x.split()) <= text_max_len)]   #원문\n",
    "data = data[data['headlines'].apply(lambda x: len(x.split()) <= summary_max_len)]   #요약문\n",
    "\n",
    "\n",
    "#출력부============================\n",
    "print(\"*\" * 60)\n",
    "print(\"<DATA INFO>\")\n",
    "print(data.info())\n",
    "print(\"*\" * 60)\n",
    "#End=============================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "announced-deficit",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 시작 · 종료 토큰을 추가한 디코더용 데이터 추가\n",
    "***\n",
    "+ 시작 토큰(`sostoken`)과 종료 토큰(`eostoken`)을 추가한 데이터를 생성하고 디코더 모델에 입력할 새로운 속성을 추가 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "southwest-session",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "      <td>saurav kant alumnus upgrad iiit pg program mac...</td>\n",
       "      <td>sostoken upgrad learner switches to career in ...</td>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "      <td>new zealand defeated india wickets fourth odi ...</td>\n",
       "      <td>sostoken new zealand end rohit sharma led indi...</td>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "      <td>aegon life iterm insurance plan customers enjo...</td>\n",
       "      <td>sostoken aegon life iterm insurance plan helps...</td>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upgrad learner switches to career in ml al wit...   \n",
       "2  new zealand end rohit sharma led india match w...   \n",
       "3  aegon life iterm insurance plan helps customer...   \n",
       "\n",
       "                                                text  \\\n",
       "0  saurav kant alumnus upgrad iiit pg program mac...   \n",
       "2  new zealand defeated india wickets fourth odi ...   \n",
       "3  aegon life iterm insurance plan customers enjo...   \n",
       "\n",
       "                                       decoder_input  \\\n",
       "0  sostoken upgrad learner switches to career in ...   \n",
       "2  sostoken new zealand end rohit sharma led indi...   \n",
       "3  sostoken aegon life iterm insurance plan helps...   \n",
       "\n",
       "                                      decoder_target  \n",
       "0  upgrad learner switches to career in ml al wit...  \n",
       "2  new zealand end rohit sharma led india match w...  \n",
       "3  aegon life iterm insurance plan helps customer...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#토큰 추가 및 속성 추가============\n",
    "data['decoder_input'] = data['headlines'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['headlines'].apply(lambda x : x + ' eostoken')\n",
    "#End===============================\n",
    "\n",
    "\n",
    "#출력부===========================\n",
    "data.head(3)\n",
    "#End=============================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-cincinnati",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 데이터 셔플링\n",
    "***\n",
    "+ 올바른 학습을 위해 데이터를 섞어 줍니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "treated-playing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numpy로 변환========================\n",
    "encoder_input = np.array(data['text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블\n",
    "#End=================================\n",
    "\n",
    "\n",
    "#데이터 shuffle======================\n",
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)   #idx 섞기\n",
    "\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]\n",
    "#End================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-solomon",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 학습 데이터와 테스트 데이터 분리 하기\n",
    "***\n",
    "+ 학습 데이터 68,675개, 테스트 데이터 17,168개로 분리 하였습니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "variable-asbestos",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "train X data num: 68675 \ttrain Y data num: 68675\n",
      "test X data num: 17168 \ttest Y data num: 17168\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(len(encoder_input) * 0.2)   #20% 분할\n",
    "\n",
    "\n",
    "#학습 데이터======================\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "#End==============================\n",
    "\n",
    "\n",
    "#테스트 데이터====================\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "#End==============================\n",
    "\n",
    "\n",
    "#출력부===========================\n",
    "print(\"*\" * 60)\n",
    "print(\n",
    "    \"train X data num:\", len(encoder_input_train),\n",
    "    \"\\ttrain Y data num:\", len(decoder_input_train)\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"test X data num:\", len(encoder_input_test),\n",
    "    \"\\ttest Y data num:\", len(decoder_input_test)\n",
    ")\n",
    "print(\"*\" * 60)\n",
    "#End=============================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-wallace",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 3.2. 단어 사전 생성 및 문장 토큰화\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 문장을 모델이 이해할 수 있도록 토큰화 해줍니다. 따라서, 우선적으로 단어사전을 생성하여 줍니다. 또한, 단어 사용빈도를 확인하여, 등장 빈도가 약 3% 이하인 단어는 제외하여 단어사전을 생성합니다. 이러한 과정을 원문과 요약문 별로 진행합니다.\n",
    "</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-cambridge",
   "metadata": {},
   "source": [
    "### 3.2.1. 원문에 대한 문장 토큰화\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 원문에 대한 토큰화를 진행합니다. 단어 사용빈도를 확인하여 22,000개의 단어로 단어사전을 생성합니다. 이후 자연어로 되어있는 문장을 토큰화 하여 줍니다.\n",
    "</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-harbor",
   "metadata": {},
   "source": [
    "#### 단어 사용 빈도 확인 하기\n",
    "***\n",
    "+ 전체 단어는 총 64,776개 입니다.\n",
    "\n",
    "\n",
    "+ 전체 데이터에서 5회 이하 사용된 단어의 수는 42,389개 이며, 약 3.33% 빈도로 사용 되었습니다.\n",
    "\n",
    "\n",
    "+ 6회 이상 사용된 단어는 총 22,387개로 해당 단어 만으로 다시 단어사전을 재정의 하고자 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "remarkable-scholarship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "단어 집합(vocabulary)의 크기 : 64767\n",
      "등장 빈도가 5번 이하인 희귀 단어의 수: 42476\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 22291\n",
      "단어 집합에서 희귀 단어의 비율: 65.58278135470223\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.354488677920944\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "#단어 사용 빈도 확인==============\n",
    "def print_word_rate(tokenizer, word_num):\n",
    "    threshold = word_num\n",
    "    total_cnt = len(tokenizer.word_index)   #단어 빈도\n",
    "    rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "    total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "    rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "    # 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "    for key, value in tokenizer.word_counts.items():\n",
    "        total_freq = total_freq + value\n",
    "\n",
    "        if(value < threshold):\n",
    "            rare_cnt = rare_cnt + 1\n",
    "            rare_freq = rare_freq + value\n",
    "\n",
    "\n",
    "    #출력부===========================\n",
    "    print(\"*\" * 60)\n",
    "    print('단어 집합(vocabulary)의 크기 :', len(tokenizer.word_index))\n",
    "    print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "    print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "    print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "    print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)\n",
    "    print(\"*\" * 60)\n",
    "    #End==============================\n",
    "    \n",
    "    return None\n",
    "#End==============================\n",
    "\n",
    "\n",
    "#토크나이저=======================\n",
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) #학습 데이터 토큰화\n",
    "#End==============================\n",
    "\n",
    "\n",
    "print_word_rate(src_tokenizer, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-photography",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 단어사전 생성\n",
    "***\n",
    "+ 총 22,000개의 단어가 등록된 단어사전을 생성 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "technological-texture",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = 20000\n",
    "src_tokenizer = Tokenizer(num_words=20000) # 단어 집합의 크기를 22,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-chess",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 문장을 토큰으로 변환 하기\n",
    "***\n",
    "+ 단어 사전을 기반으로 학습 데이터와 테스트 데이터를 토큰으로 변환 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "supported-niger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "chechen republic leader ramzan kadyrov proposed death penalty recruiters terrorist groups recruiters must bear stronger punishment terrorist starts clockwork bomb someone takes hostages commits acts sabotage added earlier kadyrov claimed militants cannot cured destroyed\n",
      "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓\n",
      "[16198, 1960, 98, 9207, 15441, 735, 155, 1384, 19192, 1022, 1113, 19192, 654, 3015, 5093, 2658, 1022, 4305, 1243, 851, 1729, 13646, 3738, 12237, 4, 33, 15441, 40, 903, 229, 13647, 2235]\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "print(\"*\" * 60)\n",
    "print(encoder_input_train[0])   #변환 이전 샘플\n",
    "\n",
    "\n",
    "#토큰으로 변환 과정==========\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train)\n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "#End=========================\n",
    "\n",
    "\n",
    "print(\"↓\" * 35)\n",
    "print(encoder_input_train[0])   #변환 이후 샘플\n",
    "print(\"*\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organizational-convention",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 3.2.2. 요약문에 대한 문장 토큰화\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 요약문에 대한 토큰화를 진행합니다. 단어 사용빈도를 고려하여 12,000개의 단어로 단어사전을 생성합니다. 이후 자연어로 되어있는 문장을 토큰화 하여 줍니다.\n",
    "</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-millennium",
   "metadata": {},
   "source": [
    "#### 단어 사용 빈도 확인 하기\n",
    "***\n",
    "+ 전체 단어는 총 28,526개 입니다.\n",
    "\n",
    "\n",
    "+ 전체 데이터에서 3회 이하 사용된 단어의 수는 16,220개 이며, 약 3.52% 빈도로 사용 되었습니다.\n",
    "\n",
    "\n",
    "+ 4회 이상 사용된 단어는 총 12,306개로 해당 단어 만으로 다시 단어사전을 재정의 하고자 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "undefined-sierra",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "단어 집합(vocabulary)의 크기 : 28529\n",
      "등장 빈도가 3번 이하인 희귀 단어의 수: 16207\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 12322\n",
      "단어 집합에서 희귀 단어의 비율: 56.80886115882085\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.5269640934063173\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "#토크나이저=======================\n",
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "#End==============================\n",
    "\n",
    "\n",
    "print_word_rate(tar_tokenizer, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-pathology",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 단어사전 생성\n",
    "***\n",
    "+ 총 12,000개의 단어가 등록된 단어사전을 생성 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ahead-moderator",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_vocab = 12000\n",
    "tar_tokenizer = Tokenizer(num_words=tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-program",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 문장을 토큰으로 변환 하기\n",
    "***\n",
    "+ 단어 사전을 기반으로 학습 데이터와 테스트 데이터를 토큰으로 변환 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "muslim-plasma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "sostoken give death penalty to terrorist recruiters chechen leader\n",
      "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓\n",
      "[1, 265, 86, 1017, 3, 1006, 10812, 120]\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "print(\"*\" * 60)\n",
    "print(decoder_input_train[0])   #변환 이전 샘플\n",
    "\n",
    "\n",
    "#토큰으로 변환 과정==========\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train)   #디코더 학습 X\n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)   #디코더 학습 Y\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)   #디코더 테스트 X\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)   #디코더 테스트 Y\n",
    "#End=========================\n",
    "\n",
    "\n",
    "print(\"↓\" * 35)\n",
    "print(decoder_input_train[0])   #변환 이후 샘플\n",
    "print(\"*\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sensitive-bolivia",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 3.3. 데이터 전처리를 통한 학습 데이터 생성2\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 최종적으로 비어 있는 데이터를 제외하여 주고 문장에 패딩을 추가합니다. 원문의 최대 길이는 40, 요약문의 최대 길이는 11로 설정하고 문장의 뒷 부분에 패딩을 추가합니다.\n",
    "</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-savage",
   "metadata": {},
   "source": [
    "#### 빈 데이터 삭제하기\n",
    "***\n",
    "+ 시작(`sostoken`) 또는 종료(`eostoken`) 토큰만 남아 길이가 1인 문장은 제외해 줍니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "blank-norfolk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "삭제할 훈련 데이터의 개수 : 0\n",
      "삭제할 테스트 데이터의 개수 : 0\n",
      "************************************************************\n",
      "\n",
      "\n",
      "************************************************************\n",
      "훈련 데이터의 개수 : 68675\n",
      "훈련 레이블의 개수 : 68675\n",
      "테스트 데이터의 개수 : 17168\n",
      "테스트 레이블의 개수 : 17168\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "#토큰으로 변환된 데이터 중 문장의 길이가 1인 것만 리스트화=====\n",
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "#End===========================================================\n",
    "\n",
    "\n",
    "#길이가 1인 문장 제거하기======================================\n",
    "encoder_input_train = np.delete(encoder_input_train, drop_train, axis=0)   #인코더 학습 X\n",
    "decoder_input_train = np.delete(decoder_input_train, drop_train, axis=0)   #디코더 학습 X\n",
    "decoder_target_train = np.delete(decoder_target_train, drop_train, axis=0)   #디코더 학습 Y\n",
    "\n",
    "encoder_input_test = np.delete(encoder_input_test, drop_test, axis=0)   #인코더 테스트 X\n",
    "decoder_input_test = np.delete(decoder_input_test, drop_test, axis=0)   #디코더 테스트 X\n",
    "decoder_target_test = np.delete(decoder_target_test, drop_test, axis=0)   #디코더 테스트 Y\n",
    "#End===========================================================\n",
    "\n",
    "\n",
    "#출력부=======================\n",
    "print(\"*\" * 60)\n",
    "print('삭제할 훈련 데이터의 개수 :', len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :', len(drop_test))\n",
    "print(\"*\" * 60)\n",
    "\n",
    "print(\"\\n\\n\" + \"*\" * 60)\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))\n",
    "print(\"*\" * 60)\n",
    "#End=========================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "soviet-annotation",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 패딩 추가 하기\n",
    "***\n",
    "+ 원문은 최대 길이 40, 요약문은 최대 길이 11로 설정하여 패딩을 추가 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "physical-vector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "[16198  1960    98  9207 15441   735   155  1384 19192  1022  1113 19192\n",
      "   654  3015  5093  2658  1022  4305  1243   851  1729 13646  3738 12237\n",
      "     4    33 15441    40   903   229 13647  2235     0     0     0     0\n",
      "     0     0     0     0]\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "#패딩추가 text_max_len: 40, summary_max_len: 11\n",
    "padding = \"post\"\n",
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding=padding)\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding=padding)\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen=summary_max_len, padding=padding)\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen=summary_max_len, padding=padding)\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen=summary_max_len, padding=padding)\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen=summary_max_len, padding=padding)\n",
    "\n",
    "\n",
    "#출력부==================\n",
    "print(\"*\" * 60)\n",
    "print(encoder_input_train[0])\n",
    "print(\"*\" * 60)\n",
    "#End====================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-planet",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 4. 모델 설계 및 학습\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 예제에서는 seq2seq에 어텐션을 결합한 형태의 모델을 사용 합니다. 어텐션은 RNN의 장기 의존성 문제를 해결하고자 인코더의 상태를 전부 반영할 수 있도록 해줍니다. 모델은 크게 seq2seq에 해당하는 인코더와 디코더로 구분되고 어텐션 레이어가 존재 합니다. [그림 1]은 어텐션을 결합한 seq2seq 모델을 시각화 한 것입니다.\n",
    "</span>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "<img src=\"./img/model.png\" width=800></img>\n",
    "\n",
    "[그림 1] 어텐션을 결합한 seq2seq 모델\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "female-saskatchewan",
   "metadata": {},
   "source": [
    "#### 인코더 설계\n",
    "***\n",
    "+ 원문은 최대 길이 40, 요약문은 최대 길이 11로 설정하여 패딩을 추가 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "apart-borough",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 128   #임베딩 벡터 크기\n",
    "hidden_size = 256   #유닛 수\n",
    "\n",
    "\n",
    "#Encoding Model=======================\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
    "#End=================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infrared-nightlife",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 디코더 설계\n",
    "***\n",
    "+ 원문은 최대 길이 40, 요약문은 최대 길이 11로 설정하여 패딩을 추가 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "vertical-wiring",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decoding Model=======================\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n",
    "#End=================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-stable",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 어텐션 및 출력부 설계\n",
    "***\n",
    "+ 원문은 최대 길이 40, 요약문은 최대 길이 11로 설정하여 패딩을 추가 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "occupational-raleigh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "domestic-french",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 모델 통합 하기\n",
    "***\n",
    "+ 원문은 최대 길이 40, 요약문은 최대 길이 11로 설정하여 패딩을 추가 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "favorite-justice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 40, 128)      2560000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 40, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 40, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    1536000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 40, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 256),  131328      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 12000)  6156000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 12,222,432\n",
      "Trainable params: 12,222,432\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-hollow",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 5. 모델 학습\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 앞서 생성한 모델을 학습하여 줍니다. 옵티마이저로 'Adagrad'의 학습률이 급격하게 줄어드는 문제를 해결하기 위해 G. Hintion이 제시한 'RMSProp'를 사용합니다. 또한 콜백함수를 사용하여 검증 데이터에 대한 손실 값이 2회 이상 증가할 경우 학습을 조기종료 합니다.\n",
    "</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-twins",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 모델 학습\n",
    "***\n",
    "+ 옵티마이저로 `rmsprop`을 사용 합니다.\n",
    "\n",
    "\n",
    "+ `EarlyStopping`을 통해 검증 데이터의 손실이 줄어들지 않고 증가하는 현상이 2회 관측되면 학습을 조기종료 합니다.\n",
    "\n",
    "<br>\n",
    "\n",
    "> RMSProp는 G. Hinton이 제안한 것으로 AdaGrad의 시간이 지날수록 학습률이 급격하게 감소하는 문제가 존재하여,\n",
    "이를 해결하기 위해 이전 변화량과 현재 변화량의 지수 평균으로 학습률이 급격하게 \n",
    "감소하는 것을 방지하는 옵티마이저이다[1].\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fancy-excellence",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "269/269 [==============================] - 79s 263ms/step - loss: 6.5701 - val_loss: 5.7224\n",
      "Epoch 2/32\n",
      "269/269 [==============================] - 70s 261ms/step - loss: 5.6912 - val_loss: 5.3964\n",
      "Epoch 3/32\n",
      "269/269 [==============================] - 71s 263ms/step - loss: 5.2901 - val_loss: 5.0742\n",
      "Epoch 4/32\n",
      "269/269 [==============================] - 71s 264ms/step - loss: 4.9858 - val_loss: 4.8832\n",
      "Epoch 5/32\n",
      "269/269 [==============================] - 71s 263ms/step - loss: 4.7399 - val_loss: 4.7277\n",
      "Epoch 6/32\n",
      "269/269 [==============================] - 71s 264ms/step - loss: 4.5318 - val_loss: 4.5996\n",
      "Epoch 7/32\n",
      "269/269 [==============================] - 71s 263ms/step - loss: 4.3565 - val_loss: 4.4894\n",
      "Epoch 8/32\n",
      "269/269 [==============================] - 71s 264ms/step - loss: 4.1946 - val_loss: 4.4135\n",
      "Epoch 9/32\n",
      "269/269 [==============================] - 71s 262ms/step - loss: 4.0640 - val_loss: 4.3396\n",
      "Epoch 10/32\n",
      "269/269 [==============================] - 71s 263ms/step - loss: 3.9408 - val_loss: 4.2868\n",
      "Epoch 11/32\n",
      "269/269 [==============================] - 71s 264ms/step - loss: 3.8271 - val_loss: 4.2353\n",
      "Epoch 12/32\n",
      "269/269 [==============================] - 71s 264ms/step - loss: 3.7252 - val_loss: 4.1957\n",
      "Epoch 13/32\n",
      "269/269 [==============================] - 70s 262ms/step - loss: 3.6326 - val_loss: 4.1695\n",
      "Epoch 14/32\n",
      "269/269 [==============================] - 71s 264ms/step - loss: 3.5430 - val_loss: 4.1368\n",
      "Epoch 15/32\n",
      "269/269 [==============================] - 71s 264ms/step - loss: 3.4708 - val_loss: 4.1205\n",
      "Epoch 16/32\n",
      "269/269 [==============================] - 71s 264ms/step - loss: 3.3923 - val_loss: 4.1010\n",
      "Epoch 17/32\n",
      "269/269 [==============================] - 71s 263ms/step - loss: 3.3277 - val_loss: 4.0784\n",
      "Epoch 18/32\n",
      "269/269 [==============================] - 71s 263ms/step - loss: 3.2650 - val_loss: 4.0766\n",
      "Epoch 19/32\n",
      "269/269 [==============================] - 71s 263ms/step - loss: 3.2015 - val_loss: 4.0664\n",
      "Epoch 20/32\n",
      "269/269 [==============================] - 71s 263ms/step - loss: 3.1492 - val_loss: 4.0600\n",
      "Epoch 21/32\n",
      "269/269 [==============================] - 71s 263ms/step - loss: 3.1007 - val_loss: 4.0457\n",
      "Epoch 22/32\n",
      "269/269 [==============================] - 71s 263ms/step - loss: 3.0489 - val_loss: 4.0461\n",
      "Epoch 23/32\n",
      "269/269 [==============================] - 71s 263ms/step - loss: 2.9979 - val_loss: 4.0438\n",
      "Epoch 24/32\n",
      "269/269 [==============================] - 71s 264ms/step - loss: 2.9547 - val_loss: 4.0476\n",
      "Epoch 25/32\n",
      "269/269 [==============================] - 71s 264ms/step - loss: 2.9178 - val_loss: 4.0382\n",
      "Epoch 26/32\n",
      "269/269 [==============================] - 71s 264ms/step - loss: 2.8774 - val_loss: 4.0467\n",
      "Epoch 27/32\n",
      "269/269 [==============================] - 71s 263ms/step - loss: 2.8366 - val_loss: 4.0406\n",
      "Epoch 00027: early stopping\n"
     ]
    }
   ],
   "source": [
    "#모델 컴파일=========================\n",
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='sparse_categorical_crossentropy'\n",
    ")\n",
    "#End=================================\n",
    "\n",
    "\n",
    "#콜백 함수===========================\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "#End=================================\n",
    "\n",
    "\n",
    "#모델 학습===========================\n",
    "history = model.fit(\n",
    "    x=[encoder_input_train, decoder_input_train],\n",
    "    y=decoder_target_train,\n",
    "    validation_data=([encoder_input_test, decoder_input_test],decoder_target_test),\n",
    "    batch_size=256,\n",
    "    callbacks=[es],\n",
    "    epochs=32\n",
    ")\n",
    "#End================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-fiction",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 학습 결과 시각화\n",
    "***\n",
    "+ 학습 데이터와 검증 데이터에 대한 학습 진행에 따른 손실 값을 시각화 한 것입니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "respective-northeast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-currency",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 6. 모델 평가\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 학습이 완료된 모델을 평가하고자 합니다. 우선, 학습데이터에 대한 손실 값은 2.836이며, 검증 데이터에 대한 손실 값은 4.04 입니다. 임의의 5개 문장을 사용하여, 어텐션 모델의 추상적 요약을 추출적 요약과 비교하여 모델을 평가하고자 합니다. 평가지표는 '문법 오류 정도'와 '단어 포함 정도'를 사용하고자 합니다.\n",
    "</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-control",
   "metadata": {},
   "source": [
    "### 6.1. 인퍼런스 단계 모델 및 필요 함수 생성\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 요약문이 존재하지 않는 문장을 요약하기 위한 인퍼런스 단계의 모델을 생성합니다. 또한, 토큰으로 되어있는 문장을 자연어로 변경하기 위한 함수를 생성합니다.\n",
    "</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-wilson",
   "metadata": {},
   "source": [
    "#### 인퍼런스 단계의 모델 생성\n",
    "***\n",
    "+ 모델의 테스트 단계에서 사용할 모델을 생성 해 줍니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "wicked-destiny",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-connecticut",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 필요 함수 생성\n",
    "***\n",
    "+ 모델이 출력한 토큰으로 된 문장을 다시 자연어로 변환하기 위한 함수를 생성 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "proper-richardson",
   "metadata": {},
   "outputs": [],
   "source": [
    "#단어 사전===============================\n",
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음\n",
    "#End=====================================\n",
    "\n",
    "\n",
    "#단어 시퀀스 함수========================\n",
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if (sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (summary_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence\n",
    "#End=====================================\n",
    "\n",
    "\n",
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환=====\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if (i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "#End============================================\n",
    "\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환===\n",
    "def seq2summary(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if ((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp\n",
    "#End============================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-testing",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 6.2. 추상적 요약과 추출적 요약을 비교한 모델 평가\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 임의의 문장 다섯 개와 그에 대한 추출적 요약과 추상적 요약을 출력하여 이를 토대로 모델을 평가하고자 합니다. 평가지표는 '문법 오류 정도'와 '단어 포함 정도'를 사용하고자 합니다. 문법 오류 정도를 파악하기 위해 Superrrokie' 사이트의 문법 검사기를 사용하였습니다(https://www.superookie.com/en-grammarcheck). 해당 문법 검사기에서 지적한 개수를 문법 오류 정도로 사용 하였습니다. 또한 단어 일치 정도를 판단하기 위해 실제 요약문의 동사 및 명사와 모델 요약문의 동사 및 명사의 일치 개수를 사용 하였습니다.\n",
    "</span><br><br>\n",
    "\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 그 결과 다섯 문장에 대한 어텐션 모델의 요약문의 평균 문법 오류 정도는 0.2였으며, 단어 일치 정도는 1.8 이었습니다. 추출적 요약의 평균 문법 오류 정도는 0이었으며, 단어 일치 정도는 3.6입니다. 평가 지표를 토대로 추상적 요약과 추출적 요약을 비교하였을 때, 추출적 요약이 더 잘 요약한 것이라 판단할 수 있습니다. 그러나 추출적 요약이 전혀 다른 문장을 제시하거나 하는 문제가 발생기도 하였습니다. 또한, 추상적 요약의 경우, 원문을 바탕으로 새로운 문장을 제시한다는 점과 원문의 의미를 잘 요약한 경우가 있기 때문에, 충분히 개선의 여지가 있다고 할 수 있습니다. 다음은 세 원문과 요약문에 대한 추상적 요약과 추출적 요약 결과를 보여줍니다.\n",
    "</span>\n",
    "\n",
    "***\n",
    "\n",
    "<br>\n",
    "\n",
    "***\n",
    "> __Infosys, 전 CFO Bansal에 이자와 함께 12.17크루를 지불하라고 지시__\n",
    "\n",
    "> Infosys는 전 CFO인 Rajiv Bansal에게 1217만 7천 파운드의 미지급 퇴직금을 이자와 함께 지불하라는 중재 재판소의 지시를 받았습니다. Infosys는 이전에 지불한 퇴직금 520만 파운드와 손해 배상액의 환불에 대한 반소가 기각되었다고 회사 서류에서 밝혔습니다. 2015년 인포시스를 그만둔 Bansal은 퇴직금으로 1738만 달러를 받을 예정이었습니다.\n",
    "\n",
    "> _인포시스 회장, 전 CFO에 10억 달러 자산 지급(추상적 요약)_\n",
    "\n",
    "> _2015년 인포시스를 그만둔 Bansal은 퇴직금으로 1738만 달러를 받을 예정이었습니다(추출적 요약)._\n",
    "\n",
    "> __평가: 추상적 요약의 경우, 원문으로부터 새로운 문장을 생성하였으며 그 의미도 매우 잘 요약 하였다.__\n",
    "\n",
    "<br><br>\n",
    "\n",
    "> __캐터필라와 같은 로봇은 인체 내부에 약물을 전달할 수 있습니다__\n",
    "\n",
    "> 연구자들은 인체 내부에 약물을 전달할 수 있는 애벌레 같은 다리를 가진 작고 부드러운 로봇을 개발했습니다. 17mm 길이의 다족 로봇은 전자기력을 사용하여 가혹한 환경을 통과합니다. 연구원들은 장애물을 넘을 때 최대 90도까지 서 있을 수 있으며 자신보다 100배 더 무거운 짐을 들 수 있다고 주장했습니다.\n",
    "\n",
    "> _과학자들은 인간의 두뇌에 인간 로봇을 찾습니다(추상적 요약)._\n",
    "\n",
    "> _연구자들은 인체 내부에 약물을 전달할 수 있는 애벌레 같은 다리를 가진 작고 부드러운 로봇을 개발했습니다(추출적 요약)._\n",
    "\n",
    "> __평가: 추상적 요약의 경우 문법의 문제는 존재하지 않지만 문장의 의미를 이해할 수 없다.__\n",
    "\n",
    "<br><br>\n",
    "\n",
    "> __구글, 애플 모바일 칩 디자이너 영입__\n",
    "\n",
    "> 거대 기술 기업인 Google은 거의 8년 동안 회사의 칩 개발에 참여한 Apple 마이크로 아키텍트 Manu Gulati를 고용했습니다. Google은 현재 Qualcomm을 사용하는 Pixel 스마트폰과 함께 모든 제품에 타사 칩에 의존하고 있습니다. 보고서에 따르면 이 회사는 Pixel 휴대전화용 CPU를 자체 설계하는 것을 목표로 Gulati를 고용했습니다.\n",
    "\n",
    "> _구글은 플레이 지원을 위해 구글을 고용한다(추상적 요약)_\n",
    "\n",
    "> _거대 기술 기업인 Google은 거의 8년 동안 회사의 칩 개발에 참여한 Apple 마이크로 아키텍트 Manu Gulati를 고용했습니다(추출적 요약)._\n",
    "\n",
    "> __평가: 추상적 요약의 경우 새로운 인원을 고용하는 것을 잘 요약하였지만, 누구를 고용하는 가에 있어 올바르게 설명하지 못하였다.__\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "thick-spanking",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "<TEXT>\n",
      "\tInfosys has been directed by an arbitral tribunal to pay former CFO Rajiv Bansal an outstanding severance pay of Ã¢ÂÂ¹12.17 crore with interest. Infosys' counterclaim for a refund of previously paid severance amount of Ã¢ÂÂ¹5.2 crore and damages, has been rejected, a company filing said. Bansal, who quit Infosys in 2015, was supposed to get Ã¢ÂÂ¹17.38 crore in severance pay.\n",
      "\n",
      "............................................................ \n",
      "\n",
      "<HEADLINE>\n",
      "\tInfosys told to pay Ã¢ÂÂ¹12.17 cr with interest to ex-CFO Bansal\n",
      "\n",
      "............................................................ \n",
      "\n",
      "<ATTENTION HEADLINE>\n",
      "\t infosys chairman to pay crore in assets to ex cfo\n",
      "\n",
      "............................................................ \n",
      "\n",
      "<EXTRACTIVE HEADLINE>\n",
      "\tBansal, who quit Infosys in 2015, was supposed to get Ã¢ÂÂ¹17.38 crore in severance pay.\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "<TEXT>\n",
      "\tTwelve tonnes of melted chocolate covered a highway in Polish town Slupca after a lorry crashed through a traffic barrier and overturned. The driver was hospitalised with a broken arm, although no one else was wounded. The chocolate later solidified and a cleaning crew started removing it using an excavator and hot water pressure washers. \n",
      "\n",
      "............................................................ \n",
      "\n",
      "<HEADLINE>\n",
      "\t12 tonnes of chocolate cover highway as truck overturns\n",
      "\n",
      "............................................................ \n",
      "\n",
      "<ATTENTION HEADLINE>\n",
      "\t cars collapses after truck falls into truck in truck\n",
      "\n",
      "............................................................ \n",
      "\n",
      "<EXTRACTIVE HEADLINE>\n",
      "\tTwelve tonnes of melted chocolate covered a highway in Polish town Slupca after a lorry crashed through a traffic barrier and overturned.\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "<TEXT>\n",
      "\tResearchers have developed a tiny, soft robot with caterpillar-like legs that can deliver drugs inside a human body. The 17-millimetre long, multi-legged robot uses electromagnetic force to move through harsh environments. It can stand up to 90 degrees to climb over obstacles and can carry a load 100 times heavier than itself, the researchers claimed. \n",
      "\n",
      "............................................................ \n",
      "\n",
      "<HEADLINE>\n",
      "\tCaterpillar-like robot can deliver drugs inside human body\n",
      "\n",
      "............................................................ \n",
      "\n",
      "<ATTENTION HEADLINE>\n",
      "\t scientists find human robot to human brain\n",
      "\n",
      "............................................................ \n",
      "\n",
      "<EXTRACTIVE HEADLINE>\n",
      "\tResearchers have developed a tiny, soft robot with caterpillar-like legs that can deliver drugs inside a human body.\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "<TEXT>\n",
      "\tTech giant Google has hired Apple micro-architect Manu Gulati who worked on the company's chip development for nearly eight years. Google currently relies on third-party chips for all their products, with Pixel smartphones using Qualcomm. The company hired Gulati with the goal of designing its own CPUs for Pixel phones, according to reports.\n",
      "\n",
      "............................................................ \n",
      "\n",
      "<HEADLINE>\n",
      "\tGoogle hires designer behind Apple's mobile chips\n",
      "\n",
      "............................................................ \n",
      "\n",
      "<ATTENTION HEADLINE>\n",
      "\t google hires google for support to play\n",
      "\n",
      "............................................................ \n",
      "\n",
      "<EXTRACTIVE HEADLINE>\n",
      "\tTech giant Google has hired Apple micro-architect Manu Gulati who worked on the company's chip development for nearly eight years.\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "<TEXT>\n",
      "\tStanford University researchers have developed a wireless, battery-free, biodegradable sensor to monitor blood flow through an artery after blood vessel surgery. The sensor wraps around the healing vessel, where blood pulsing past pushes on its inner surface. Any irregularities in the blood vessel can be detected remotely from a device located near the skin but outside the body, scientists said.\n",
      "\n",
      "............................................................ \n",
      "\n",
      "<HEADLINE>\n",
      "\tBiodegradable sensor to monitor blood flow in arteries made\n",
      "\n",
      "............................................................ \n",
      "\n",
      "<ATTENTION HEADLINE>\n",
      "\t scientists make smart blood with blood with accuracy\n",
      "\n",
      "............................................................ \n",
      "\n",
      "<EXTRACTIVE HEADLINE>\n",
      "\tThe sensor wraps around the healing vessel, where blood pulsing past pushes on its inner surface.\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./dataset/news_summary_more.csv', encoding='iso-8859-1')   #csv 파일 불러오기\n",
    "idx_list = np.random.randint(0, len(data), size=100)\n",
    "\n",
    "print_count = 0\n",
    "for idx in idx_list:\n",
    "    text = data[\"text\"][idx]\n",
    "    headline = data[\"headlines\"][idx]\n",
    "    \n",
    "    token_text = src_tokenizer.texts_to_sequences([text])\n",
    "    token_text = pad_sequences(token_text, maxlen=text_max_len, padding=\"post\")\n",
    "    attention_text = decode_sequence(token_text.reshape(1, text_max_len))\n",
    "    extractive_text= summarize(text, words=11)\n",
    "    \n",
    "    if not extractive_text: continue;\n",
    "    print_count += 1\n",
    "    \n",
    "    print(\"\\n\\n\\n\\n\" + \"+\" * 80)\n",
    "    print(\"<TEXT>\\n\\t{0}\\n\".format(text))   #원문\n",
    "    \n",
    "    print(\".\" * 60, \"\\n\")\n",
    "    \n",
    "    print(\"<HEADLINE>\\n\\t{0}\\n\".format(headline))\n",
    "    \n",
    "    print(\".\" * 60, \"\\n\")\n",
    "    \n",
    "    print(\"<ATTENTION HEADLINE>\\n\\t{0}\\n\".format(attention_text))\n",
    "    \n",
    "    print(\".\" * 60, \"\\n\")\n",
    "    \n",
    "    print(\"<EXTRACTIVE HEADLINE>\\n\\t{0}\\n\".format(summarize(text, words=11)))\n",
    "    \n",
    "    print(\"+\" * 80)\n",
    "    if print_count > 4: break;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graphic-marking",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 8. 결론\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 어텐션을 결합한 seq2sqe 문장 요약 모델 생성 및 학습하고 이를 추출적 모델의 요약문과 비교하여 평가해 보았습니다. 평가는 임의의 다섯 문장에 대한 어텐션 모델의 요약과 추출적 요약을 비교하였으며, 평가 지표로 '문법 오류 정도'와 '단어 일치 정도'를 사용하였습니다.\n",
    "추상적 요약 모델의 평균 문법 오류 정도는 0.2였으며, 단어 일치 정도는 1.8 이었습니다. 추출적 요약의 평균 문법 오류 정도는 0이었으며, 단어 일치 정도는 3.6였습니다. 해당 지표를 바탕으로 추상적 요약과 추출적 요약을 비교하였을 때, 추출적 요약이 더 잘 요약한 것이라 할 수 있습니다. 그러나 추상적 요약의 경우 원문으로부터 새로운 문장을 생성한다는 점에서 그 어려움을 고려하여 충분히 개선 여지가 있다고 할 수 있습니다.\n",
    "</span><br><br>\n",
    "\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 또한, 평가 지표 설정과 평가에 있어 어려움이 있습니다. 자연어 생성의 경우 Loss나 Accuracy만을 통해 모델의 성능을 입증하는데에 어려움이 따릅니다. 본 예제에서 사용한 '문법 오류 정도'와 '단어 일치 정도'의 경우에도 완벽하지 못하고 문장의 완성도의 극히 일부만 평가하는 지표라 할 수 있습니다. 특히 문장이 생성되면 그 '의미'를 파악하는 것이 중요한데 이를 평가하는 것이 매우 어렵습니다. 따라서 궁극적으로 사람이 직접 모델이 생성한 문장을 보고 평가할 수밖에 없는 실정입니다. 다음은 임의의 문장 5개에 대한 어텐션 모델과 추출적 요약의 평가 결과를 제시한 것입니다.\n",
    "</span>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "|실제 요약문|어텐션 모델 요약문|문법 오류 정도|단어 일치 정도|\n",
    "|:--------:|:--------:|:--------:|:--------:|\n",
    "|Infosys told to pay Ã¢ÂÂ¹12.17 cr with interest to ex-CFO Bansal|infosys chairman to pay crore in assets to ex cfo|0|3|\n",
    "|12 tonnes of chocolate cover highway as truck overturns|cars collapses after truck falls into truck in truck|0|1|\n",
    "|Caterpillar-like robot can deliver drugs inside human body|scientists find human robot to human brain|0|1|\n",
    "|Google hires designer behind Apple's mobile chips|google hires google for support to play|0|2|\n",
    "|Biodegradable sensor to monitor blood flow in arteries made|scientists make smart blood with blood with accuracy|1|2|\n",
    "\n",
    "[표 1] 어텐션 모델 평가 결과\n",
    "\n",
    "<br><br>\n",
    "\n",
    "|실제 요약문|추출적 요약문|문법 오류 정도|단어 일치 정도|\n",
    "|:--------:|:--------:|:--------:|:--------:|\n",
    "|Infosys told to pay Ã¢ÂÂ¹12.17 cr with interest to ex-CFO Bansal|Bansal, who quit Infosys in 2015, was supposed to get Ã¢ÂÂ¹17.38 crore in severance pay.|0|2|\n",
    "|12 tonnes of chocolate cover highway as truck overturns|Twelve tonnes of melted chocolate covered a highway in Polish town Slupca after a lorry crashed through a traffic barrier and overturned.|0|5|\n",
    "|Caterpillar-like robot can deliver drugs inside human body|Researchers have developed a tiny, soft robot with caterpillar-like legs that can deliver drugs inside a human body.|0|6|\n",
    "|Google hires designer behind Apple's mobile chips|Tech giant Google has hired Apple micro-architect Manu Gulati who worked on the company's chip development for nearly eight years.|0|3|\n",
    "|Biodegradable sensor to monitor blood flow in arteries made|The sensor wraps around the healing vessel, where blood pulsing past pushes on its inner surface.|0|2|\n",
    "\n",
    "[표 2] 추출적 요약 평가 결과\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-swift",
   "metadata": {},
   "source": [
    "#### 참고문헌\n",
    "***\n",
    "[1] J. Gihun, P. Chihyun, I. Hyeonseung, \"Performance Evaluation of Machine Learning Optimizers\", Vol.24, No.3, 766-776, 2020.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seventh-visit",
   "metadata": {},
   "source": [
    "#### 형상관리 기록\n",
    "***\n",
    "+ v1_1: 초기모델\n",
    "\n",
    "\n",
    "+ v2_1: 프로젝트 데이터 적용\n",
    "\n",
    "\n",
    "+ v3_1: 기본적인 내용 작성\n",
    "\n",
    "\n",
    "+ v4_1: 내용 작성(2)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italic-gross",
   "metadata": {},
   "source": [
    "##### 회고\n",
    "***\n",
    "seq2seq 모델과 어텐션을 활용하여 문장을 요약하는 모델을 생성하고 평가하여 보았습니다. 두 기법 모두 처음 활용하는 것이라 새로운 것을 적용하기 보다는 이해하는 것에 중점을 두고 예제를 진행하였습니다. 그럼에도 불구하고 여전히 seq2seq, 어텐션을 정확하게 이해하진 못하였습니다. 모델의 구성이 상당히 복잡하고 그 작동 원리를 이해하는 것에 어려움이 있습니다. 또한 추출적 요약의 경우에는 라이브러리를 호출만 하면 바로 사용할 수 있다는 점에서 상당히 편한 것 같습니다. 그리고 자연어 처리에 있어 그 평가가 매우 어려움을 다시금 느꼈습니다. 자연어란 결국 말의 '의미'를 이해한 다는 것인데 이런 추상적인 것을 계량적으로 평가한 다는 것에 있어 어쩔 수 없이 사람의 개입이 많이 필요한 것 같습니다.\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
