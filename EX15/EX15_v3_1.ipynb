{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "missing-melbourne",
   "metadata": {},
   "source": [
    "#  Transformer를 이용한 한국어 챗봇 생성 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earned-improvement",
   "metadata": {},
   "source": [
    "#### 초록\n",
    "***\n",
    "<span style=\"font-size:11pt; line-height:1.8;\">\n",
    "    &nbsp; &nbsp; 송영숙(2018)이 제시한 한국어 문장 데이터셋 『Chatbot data for Korean v1』을 사용하여 트랜스포머 챗봇 모델을 생성, 학습, 평가를 진행하였다. 트랜스포머 모델의 원리와 작동 방식과 원리 설명에 초점을 두었다. 데이터 분석, 전처리, 모델 생성 및 학습, 문장생성 능력 확인 순으로 진행하여, 최종 8,147개의 단어, 9,084개의 문장 데이터를 이용하였다. 모델 문장생성 능력 확인을 위해 '밥 먹었니?', '너 누구야?', '안녕~' 등의 문장을 입력한 결과, '배고프지 않아요.', '저는 마음을 이어주는 위로봇입니다.', '안녕하세요.' 등 상당히 자연스러운 문장을 생성하는 것을 확인하였다.\n",
    "</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-documentation",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1. 서론\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 본 예제는 트랜스포머(Transformer)를 이용하여 한국어 챗봇 모델을 생성하고 모델이 그럴듯한 문장을 생성하는 것을 목표로 합니다. 모델의 개선 또는 새로운 기법의 적용보다는 '트랜스포머'의 기본적인 작동 방식과 원리를 이해하는 것에 초점을 두었습니다. 따라서, 트랜스포머의 원리를 본 예제의 작성자가 이해하는 것을 바탕으로 그림과 설명을 통해 풀어나가고자 합니다. 'RNN', 'seq2seq', 'Attention`에 대한 개념을 숙지하고 있다면 트랜스포머를 보다 쉽게 이해할 수 있을 것입니다. 예제의 진행 순서는 다음과 같습니다.\n",
    "</span><br><br>\n",
    "\n",
    "\n",
    "> _1. 데이터 분석_\n",
    ">\n",
    "> _2. 데이터 전처리_\n",
    ">\n",
    "> _3. 모델 생성_\n",
    ">\n",
    "> _4. 모델 학습 및 평가_\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-retention",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2. 데이터 분석\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 예제에서 사용하는 데이터는 송영숙(2018)이 제시한 『Chatbot data for Korean v1』을 이용합니다. 데이터는 질문과 대답 그리고 질문의 평상, 긍정, 부정에 대한 0에서 2사이의 값으로 이루어져 있습니다. 예제에서는 질문과 대답 데이터만을 이용합니다. 레코드 수는 총 11,823개이며 결측치는 없습니다.\n",
    "</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-hypothetical",
   "metadata": {},
   "source": [
    "#### 필요 라이브러리 호출\n",
    "***\n",
    "+ 예제에 필요한 라이브러리를 호출 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "provincial-contamination",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os   #디렉토리 관리\n",
    "import re   #문자열 정규식\n",
    "\n",
    "import numpy as np   #행렬 연산\n",
    "import pandas as pd   #데이터 프레임\n",
    "import matplotlib.pyplot as plt   #데이터 시각화\n",
    "\n",
    "import tensorflow as tf   #신경망\n",
    "import tensorflow_datasets as tfds   #단어장 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-playback",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 데이터 불러오기\n",
    "***\n",
    "+ 예제에 사용하는 데이터를 불러 옵니다.\n",
    "\n",
    "\n",
    "+ 질문(`Q`)과 대답(`A`) 그리고 일상(0), 부정(1), 긍정(2)의 도메인을 가지는 `label`로 구성되어 있으며 본 예제에서는 질문(`Q`)과 대답(`A`) 데이터만 이용합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sought-cycle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3861</th>\n",
       "      <td>입 안이 다 헐었어</td>\n",
       "      <td>요즘 피곤하신가봐요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>나 비만이야</td>\n",
       "      <td>건강하게 운동해보세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>너도 상사 있어</td>\n",
       "      <td>제가 상사예요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3172</th>\n",
       "      <td>여자친구랑 전화 안 받네.</td>\n",
       "      <td>걱정되겠어요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7456</th>\n",
       "      <td>이별 후 3개월이 지났는데.</td>\n",
       "      <td>여전히 힘든가봅니다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Q             A  label\n",
       "3861       입 안이 다 헐었어   요즘 피곤하신가봐요.      0\n",
       "501            나 비만이야  건강하게 운동해보세요.      0\n",
       "949          너도 상사 있어      제가 상사예요.      0\n",
       "3172   여자친구랑 전화 안 받네.       걱정되겠어요.      0\n",
       "7456  이별 후 3개월이 지났는데.   여전히 힘든가봅니다.      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"./dataset/transformer_chatbot/data/ChatbotData.csv\")\n",
    "dataset.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tired-composite",
   "metadata": {},
   "source": [
    "#### 학습 데이터 출처\n",
    "***\n",
    "+ YeongSook Song, Chatbot_data_for_Korean v1.0(2018), https://github.com/songys/Chatbot_data\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-yorkshire",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 레코드 수 및 결측치 확인\n",
    "***\n",
    "+ 레코드 수는 총 11,823개 이며, 결측치는 없습니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "contemporary-submission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11823 entries, 0 to 11822\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Q       11823 non-null  object\n",
      " 1   A       11823 non-null  object\n",
      " 2   label   11823 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 277.2+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respiratory-affiliation",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 3. 데이터 전처리\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 데이터셋을 모델에 입력하기 위해서 데이터 전처리 과정을 수행합니다. 전처리 순서는 '정규식을 이용한 문장 전처리', '단어사전 생성', '문장 길이에 따른 정제', '토크나이저화' 입니다.\n",
    "</span><br><br>\n",
    "\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 문장 길이를 확인한 결과, 질문에 대한 문장 분포의 최대값이 8개의 단어이며, 대답에 대한 문장 분포 최대값이 10개 였습니다. 따라서, 문장의 최대 길이를 10으로 설정하였습니다. 단어사전의 단어 수는 시작, 종료 토큰을 포함하여 총 8,147개 였으며, 앞서 설정한 문장의 최대 길이 10개의 단어에 근거하여 11개 이상의 단어로 이루어진 문장은 제외 하였습니다. 최종 9,104개의 문장을 얻었습니다. 해당 데이터를 바탕으로 자연어 문장을 정수형태로 바꾼 후 데이터셋을 생성하였습니다.\n",
    "</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-independence",
   "metadata": {},
   "source": [
    "#### 정규식을 이용한 문장 전처리\n",
    "***\n",
    "+ 영문, 한글, 숫자 및 문장에서 주로 사용되는 기호를 제외한 문자는 제거 합니다.\n",
    "\n",
    "\n",
    "+ 전처리가 실시된 데이터 샘플을 출력 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beginning-telephone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Question: 12시 땡! ===> 1 2 시 땡 !\n",
      "Answer: 하루가 또 가네요. ===> 하루가 또 가네요 .\n",
      "**************************************************\n",
      "Question len: 11823\tAnswer len: 11823\n"
     ]
    }
   ],
   "source": [
    "#전처리 함수===========================\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = re.sub(r\"([0-9?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[^a-zA-Zㄱ-ㅎ가-힣0-9?.!,]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence\n",
    "#End===================================\n",
    "\n",
    "\n",
    "#문장 전처리===========================\n",
    "questions, answers = [], []\n",
    "for idx, row in dataset.iterrows():\n",
    "    questions.append(preprocess_sentence(row[\"Q\"]))\n",
    "    answers.append(preprocess_sentence(row[\"A\"]))\n",
    "#End===================================\n",
    "\n",
    "\n",
    "#출력부================================\n",
    "print(\"*\" * 50)\n",
    "print(\"Question: {0} ===> {1}\".format(dataset[\"Q\"][0], questions[0]))\n",
    "print(\"Answer: {0} ===> {1}\".format(dataset[\"A\"][0], answers[0]))\n",
    "print(\"*\" * 50)\n",
    "print(\"Question len: {0}\\tAnswer len: {1}\".format(len(questions), len(answers)))\n",
    "#End==================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-envelope",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 문장 길이 확인하기\n",
    "***\n",
    "+ 질문(`Question`)와 대답(`Answer`)의 문장 길이를 확인합니다.\n",
    "\n",
    "\n",
    "+ 질문(`Question`)의 경우 가장 긴 문장의 길이가 16개의 단어이며, 대답(`Answer`)의 경우 24개의 단어 입니다.\n",
    "\n",
    "\n",
    "+ 문장 길이의 분포(Box Plot)를 확인한 결과, 질문(`Question`)의 경우 최대값이 8개의 단어이며 대답(`Answer`)의 10개의 단어입니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "regulation-claim",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "question min len: 1\n",
      "question max len: 16\n",
      "question avg len: 3.9808001353294427\n",
      "\n",
      "answer min len: 1\n",
      "answer max len: 24\n",
      "answer avg len: 4.720375539203248\n",
      "************************************************************\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x648 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "question_len = [len(s.split()) for s in questions]   #원문에 대한 문장 길이\n",
    "answers_len = [len(s.split()) for s in answers]   #요약문에 대한 문장 길이\n",
    "\n",
    "\n",
    "#출력부============================\n",
    "print(\"*\" * 60)\n",
    "print('question min len: {}'.format(np.min(question_len)))\n",
    "print('question max len: {}'.format(np.max(question_len)))\n",
    "print('question avg len: {}'.format(np.mean(question_len)))\n",
    "\n",
    "print('\\nanswer min len: {}'.format(np.min(answers_len)))\n",
    "print('answer max len: {}'.format(np.max(answers_len)))\n",
    "print('answer avg len: {}'.format(np.mean(answers_len)))\n",
    "print(\"*\" * 60)\n",
    "#End==============================\n",
    "\n",
    "\n",
    "#시각화===========================\n",
    "data_list = (question_len, answers_len)\n",
    "title_list = (\"Question\", \"Answer\")\n",
    "\n",
    "plt.figure(figsize=(11, 9))\n",
    "plt.suptitle(\"<Fig. 1> Sentence Length\", fontsize=14)\n",
    "plt.subplots_adjust(top=0.9, wspace=0.2)\n",
    "\n",
    "for idx, data in enumerate(data_list):\n",
    "    idx += 1\n",
    "    plt.subplot(2, 2, idx)\n",
    "    \n",
    "    plt.boxplot(data)\n",
    "    plt.title(title_list[idx-1])\n",
    "    \n",
    "    plt.subplot(2, 2, idx + 2)\n",
    "    plt.hist(data, bins=40)\n",
    "    plt.xlabel(\"length of samples\")\n",
    "    plt.ylabel(\"number of samples\")\n",
    "\n",
    "plt.show()\n",
    "#End=============================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-rider",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 단어사전 생성하기\n",
    "***\n",
    "+ `SubwordTextEncoder`를 이용하여 단어 사전을 생성합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "august-costs",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    questions + answers,\n",
    "    target_vocab_size=8192   #단어사전 크기\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-christmas",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 시작, 종료 토큰 추가\n",
    "***\n",
    "+ 시작과 종료 토큰을 추가합니다.\n",
    "\n",
    "\n",
    "+ 최종 단어사전의 크기는 8,147개 입니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "shared-dubai",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "START_TOKEN: [8145]\n",
      "END_TOKEN: [8146]\n",
      "VOCAB SIZE: 8147\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2   #시작, 종료 토큰 추가 시의 vocab 크기\n",
    "\n",
    "\n",
    "#출력부================================\n",
    "print(\"*\" * 50)\n",
    "print('START_TOKEN:' ,START_TOKEN)\n",
    "print('END_TOKEN:' ,END_TOKEN)\n",
    "print(\"VOCAB SIZE:\", VOCAB_SIZE)\n",
    "print(\"*\" * 50)\n",
    "#End==================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romance-horizon",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 문장 필터링 및 토크나이저 생성\n",
    "***\n",
    "+ 문장의 최대 길이를 `10`으로 설정하고 그 이상의 길이에 해당하는 문장은 제외 합니다.\n",
    "\n",
    "\n",
    "+ 필터링 후의 문장 수는 총 9,104개 입니다.\n",
    "\n",
    "\n",
    "+ 자연어로 된 단어를 정수로 변경하여 줍니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "affected-daniel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "필터링 후의 질문 샘플 개수: 9084\n",
      "필터링 후의 답변 샘플 개수: 9084\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "#================================\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "        # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "        # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "        if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "            tokenized_inputs.append(sentence1)\n",
    "            tokenized_outputs.append(sentence2)\n",
    "  \n",
    "    # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_inputs, maxlen=MAX_LENGTH, padding='post'\n",
    "    )\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_outputs, maxlen=MAX_LENGTH, padding='post'\n",
    "    )\n",
    "    return tokenized_inputs, tokenized_outputs\n",
    "#End===================================\n",
    "\n",
    "\n",
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "\n",
    "\n",
    "#출력부================================\n",
    "print(\"*\" * 50)\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))\n",
    "print(\"*\" * 50)\n",
    "#End==================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-halloween",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 데이터셋 생성하기\n",
    "***\n",
    "+ 앞서 획득한 9,104개의 정수화된 문장 데이터를 데이터셋으로 만듭니다.\n",
    "\n",
    "\n",
    "+ 배치 사이즈는 64개로 설정 합니다.\n",
    "\n",
    "\n",
    "+ 지금까지 자연어로 된 문장을 정수 형태로 된 데이터셋으로 만드는 과정이 이루어졌습니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "several-metadata",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************************************************\n",
      "보조_배터리안_가지고_왔다\n",
      "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓\n",
      "[8145  187 6236 5312 7921   20  938 1092 8146    0]\n",
      "**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "#데이터셋 생성=============================================\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        #마지막 글자 제외 = END TOKEN 제외\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        #첫 번째 글자 제외 = START TOKEN 제외\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "#End=========================================================\n",
    "\n",
    "\n",
    "#출력부======================================================\n",
    "for input_data, output_data in dataset.take(1): break;\n",
    "rand_idx = np.random.randint(0, BATCH_SIZE)\n",
    "seq = input_data[\"inputs\"][rand_idx]\n",
    "\n",
    "print(\"*\" * 70)\n",
    "for word in seq.numpy():\n",
    "    try:\n",
    "        word = tokenizer.subwords[word - 1]\n",
    "        if word == \" , ,\": break;\n",
    "        print(word, end=\"\")\n",
    "    except:\n",
    "        pass\n",
    "print(\"\\n\" + \"↓\" * 35)\n",
    "print(seq.numpy())\n",
    "print(\"*\" * 70)\n",
    "#End========================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-startup",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 4. 트랜스포머 모델 생성\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 트랜스포머 모델은 크게 인코더 부분과 디코더 부분으로 이루어져 있습니다. 모델의 목표는 'seq2seq'의 '시계열 데이터를 입력하여 시계열 데이터를 얻는 것'과 동일합니다. 기본적인 아이디어는 'Attention'만을 이용하여 'seq2seq'를 수행 하는 것입니다. 또한, 기존의 'Attention'은 RNN을 이용하여 데이터의 입력이 '순차적'으로 수행되었지만, 트랜스포머의 데이터 입력은  '동시에' 혹은 '병렬적'으로 수행된다는 특징이 있습니다. 구체적인 트랜스포머의 작동 원리와 모델 생성 과정을 설명하고자 합니다.\n",
    "</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-analysis",
   "metadata": {},
   "source": [
    "### 4.1. Positional 인코딩 레이어\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; Positional 인코딩 레이어는 문장을 이루고 있는 단어들의 순서를 모델에게 알려주기 위해 사용 됩니다. Positional 인코딩 레이어의 필요성과 구체적인 사용 방법에 대해 설명하겠습니다.\n",
    "</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-tampa",
   "metadata": {},
   "source": [
    "### 4.1.1. Positional 인코딩 레이어의 존재 이유\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 앞서 트랜스포머는 데이터의 입력이 병렬적으로 이루어진다고 하였습니다. 이를 쉽게 설명한다면 '문장을 동시에 한 번에 넣는 것'이라고 할 수 있습니다. [그림 2]는 기존 RNN을 이용한 seq2seq의 데이터 입력 방식과 트랜스포머의 입력 방식을 그린 것입니다. \n",
    "</span><br><br>\n",
    "\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; RNN을 이용한 경우에는 'I', 'Love', 'You' 단어를 RNN 유닛에 단어별로 순차적으로 넣어주었습니다. 하지만 트랜스포머에서는 단어를 하나의 행렬로 묶어 한 번에 입력합니다.\n",
    "</span><br><br>\n",
    "\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 여기서 문제가 발생하는데, RNN의 경우에는 단어를 순차적으로 입력하기 때문에 모델이 단어의 순서를 알 수 있습니다. 하지만, 트랜스포머의 경우 동시에 입력되기 때문에 단어의 순서를 알 수 없습니다. 한 문장에 동일한 단어가 존재할 때, 두 단어의 임베딩 벡터 값은 동일할 것이고 모델은 그 순서를 알 수 없습니다. 이러한 문제를 해결하기 위해 Positional 인코딩 레이어가 사용됩니다.\n",
    "</span>\n",
    "\n",
    "<img src=\"./img/why_positional.png\" width=400>\n",
    "[그림 2] 기존 seq2seq의 작동 방식과 트랜스포머의 작동 방식\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "similar-caribbean",
   "metadata": {},
   "source": [
    "### 4.1.2. 구체적인 Positional 인코딩 레이어의 활용 방법\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; Positional 인코딩 레이어는 단어별 즉, 행별로 다른 값을 가지는 레이어와 입력되는 단어 임베딩을 더하여 그 순서를 구분하고자 합니다. [그림 3]은 Positional 인코딩 레이어를 통해 어떻게 순서를 구분하는지 보여줍니다. 'sentence length'는 문장의 길이 즉, 문장을 이루는 단어의 개수 입니다. 'word vector'는 단어 임베딩 벡터의 차원 수 입니다. 따라서, Posltional 인코딩 레이어의 각 행이 단어이며 그 순서를 나타내는 것입니다. 따라서 1행은 t 시점의 단어, 2행은 t + 1 시점의 단어에 해당하는 것입니다. 따라서, 각 행별로 다른 값을 가진 Positional 인코딩 레이어와 입력되는 단어 임베딩을 더하면 같은 단어라도 출력되는 값이 달라지게 됩니다.\n",
    "</span><br><br>\n",
    "\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; Positional 인코딩 레이어와 입력되는 문장 행렬은 같은 위치의 원소를 더하는 것이기 때문에 두 행렬의 크기는 동일함을 알 수 있습니다. Positional 인코딩 레이어의 패턴은 Cosin과 Sin을 이용합니다. 중요한 것은 단어에 해당하는 각 행의 값이 모두 다른 점을 이용하여 단어의 순서를 구분한다는 것입니다.\n",
    "</span>\n",
    "\n",
    "<img src=\"./img/positional.png\" width=500>\n",
    "[그림 3] Positional 인코딩 레이어와 연산 방식\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-frank",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Positional 인코딩 레이어 생성\n",
    "***\n",
    "+ Positional 인코딩 레이어를 생성합니다.\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dangerous-respect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, position, d_model):\n",
    "        #position: 행 크기(=문장 길이), d_model:  임베딩 차원\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    #(pos / 10000 ** 2i / d_model)==============================\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        #tf.pow(x, y): x ** y\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "    #End========================================================\n",
    "    \n",
    "    def positional_encoding(self, position, d_model):\n",
    "        # 각도 배열 생성\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model\n",
    "        )\n",
    "\n",
    "        # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        \n",
    "        # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        # sin과 cosine이 교차되도록 재배열\n",
    "        pos_encoding = tf.stack([sines, cosines], axis=0)   #순차대로 적재\n",
    "        pos_encoding = tf.transpose(pos_encoding, [1, 2, 0]) \n",
    "        pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):   #input과 positional encoding과 합치기\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
    "#End++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-mozambique",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 포지셔널 인코딩 레이어 시각화\n",
    "***\n",
    "+ 임베딩 크기는 512이며, 문장 길이는 10인 Positional 인코딩 레이어를 시각화 합니다.\n",
    "\n",
    "\n",
    "+ 각 행별로 그 값이 다른 것을 확인할 수 있습니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ongoing-drink",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "EMBEDDING_SIZE = 512\n",
    "\n",
    "sample_pos_encoding = PositionalEncoding(MAX_LENGTH, EMBEDDING_SIZE)\n",
    "\n",
    "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, EMBEDDING_SIZE))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-folder",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 중복 행 여부 확인하기\n",
    "***\n",
    "+ Positional 인코딩 레이어의 행 중 중복되는 행을 제거하여 그 크기 변화를 확인합니다.\n",
    "\n",
    "\n",
    "+ 그 결과, 제거된 행이 없으며, 이는 중복되는 행이 없음을 의미 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "broke-district",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "(1, 10, 512)\n",
      "↓↓↓↓↓drop duplicate data↓↓↓↓↓\n",
      "(10, 512)\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "print(\"*\" * 50)\n",
    "print(sample_pos_encoding.pos_encoding.shape)\n",
    "print(\"↓↓↓↓↓drop duplicate data↓↓↓↓↓\")\n",
    "\n",
    "#중복행 제거\n",
    "test_pd = pd.DataFrame(sample_pos_encoding.pos_encoding.numpy()[0]).copy()\n",
    "\n",
    "print(test_pd.drop_duplicates(test_pd.columns.tolist()).shape)\n",
    "print(\"*\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-financing",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 4.2. Scaled Dot Product Attention\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; Scaled Dot Product Attention은 Attention의 일종으로 단어 벡터 간 유사도를 행렬곱(Product)하고 정규화(Scale)한 것으로 이해할 수 있습니다. 우선 Attention을 설명한 후, Scaled Dot Product Attention을 구하는 방법을 설명하고자 합니다.\n",
    "</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-cartridge",
   "metadata": {},
   "source": [
    "### 4.2.1. Attention의 역할\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; Attention은 문장의 단어 간 연관 정도를 파악하는 것입니다. 그리고 연관도가 높은 단어에 집중(Attetion)하겠다는 것입니다. [그림 4]는 Atention을 도식화 한 것입니다. 'I am a boy'에서 'I'와 각 단어의 연관도를 파악한다면, '나'는 '남자'이기 때문에 'boy'와 높은 연관도를 가질 것입니다. 이러한 단어 간의 연관도는 모델이 문장을 이해하는데 도움을 줍니다. 단어의 연관도는 [그림 3]과 같이 행렬 형태로 나타내어 연산이 이루어 집니다.\n",
    "</span>\n",
    "\n",
    "<img src=\"./img/what_attention.png\" width=500>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-louisiana",
   "metadata": {},
   "source": [
    "### 4.2.2. Scaled Dot Product Attention 연산\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 구체적인 Scaled Dot Product Attention을 구하는 방법을 알아보겠습니다. 이를 구하기 위해서는 Query(Q), Key(K), Value(V), d가 이용됩니다. Query는 비교하고자 하는 단어의 벡터들, Key와 Value는 비교되는 단어의 벡터들입니다. d는 정규화를 위한 하나의 스칼라 값입니다. 단어 벡터의 크기를 병렬 수행할 수(Num Head)로 나누어 줍니다. [그림 5]는 Scaled Dot Product Attention의 연산 순서를 제시한 것입니다.\n",
    "</span><br><br>\n",
    "    \n",
    "    \n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 연산은 비교하고자 하는 단어의 벡터들(Q)와 비교 대상이 되는 단어의 벡터들의 전치행렬(K)을 행렬곱(Dot Product) 해준 후, 이를 sqrt(d)로 나누어 줍니다. 이후 Value를 곱하여 줍니다. 각 Q, K, V의 크기는 모두 동일하며, 해당 크기는 단어 벡터의 크기를 병렬 수행할 수(Num Head)로 나눈 값을 이용합니다. 논문에서는 512 크기의 단어 벡터와 8개의 Num Head를 이용하여 Q, K, V의 크기가 64입니다. 또한, Scaled Dot Product Attention 연산의 최종 출력 또한 Q, K, V와 크기가 동일한 것을 확인할 수 있습니다. [그림 5]에는 나와 있지 않지만 최종적으로 얻은 Scaled Dot Product Attention 값을 Dense 레이어에 통과 시킵니다. 아래는 Scaled Dot Product Attention의 수식을 제시한 것입니다.\n",
    "</span><br><br>\n",
    "\n",
    "$$Attention(Q, K, V) = softmax(\\frac{QK^T}{sqrt(d_k)}) V$$\n",
    "\n",
    "<br><img src=\"./img/scaled_dot.png\" width=800>\n",
    "\n",
    "[그림 5] Scaled Dot Product Attention 연산 순서\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-jersey",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Scaled Dot Product Attention 함수 생성\n",
    "***\n",
    "+ Scaled Dot Product Attention 연산을 수행하는 함수를 생성 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "chubby-baltimore",
   "metadata": {},
   "outputs": [],
   "source": [
    "#스케일드 닷 프로덕트 어텐션 함수(Q, K, V, mask)===============\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    #Q ·K product\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    # 가중치를 정규화\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)   #depth=d_k\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # 패딩에 마스크 추가\n",
    "    #Key에서 패딩열에 아주 작은 값으로 대체한다.\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    # softmax적용\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "    return output\n",
    "#End==========================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-danish",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 패딩 마스크 생성하기\n",
    "***\n",
    "+ 어텐션에서 `패딩(padding)`에 대한 유사도는 불필요하기 때문에 패딩열의 값을 작은 값으로 대체하여 softmax 출력에서 0의 확률이 나오도록 유도\n",
    "\n",
    "\n",
    "+ 패딩 위치를 `1(True)`로 출력하는 함수\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ruled-chase",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, sequence length)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-symbol",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 4.2.3. Query, Key, Value의 근원\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; Query, Key, Value는 어떻게 구하는지 알 필요가 있습니다. [그림 6]은 Query, Key, Value를 구하는 방법을 보여줍니다. 우선 앞서 설명한 Positional 인코딩 레이어와 문장 행렬이 더해진 값이 입력 됩니다. [그림 6]에서는 이해를 위해 행 크기를 1로 설정하였습니다. 행 크기가 1이란 것은 단어가 한 개만 입력된 것으로 생각할 수 있습니다. 그럼 이는 Wq, Wk, Wv 총 세 개의 Dense 레이어를 통과 합니다. Dense 레이어는 임베딩 벡터의 크기와 동일한 수의 유닛을 가집니다. 그럼이를 Num Head의 크기에 맞게 형태를 변형합니다. 논문에서는 512의 임베딩 벡터를 8개의 Num head로 나누어 8 x 64로 변형 하였습니다. 최종적으로 각 행이 Query, Key, Value에 해당하며, 총 8개의 Head가 생성된 것을 확인할 수 있습니다.\n",
    "</span>\n",
    "\n",
    "<img src=\"./img/get_qkv.png\" width=800>\n",
    "\n",
    "[그림 6] Query, Key, Value 획득 방법\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-attention",
   "metadata": {},
   "source": [
    "#### Multi Head Attention 정의\n",
    "***\n",
    "+ 앞서 설명한 Head 나누기와 Scaled Dot Product Attention을 결합하여 Multi Head Attention 레이어를 정의 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caroline-resolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    #d_model: 단어 벡터 크기, num_heads: 병렬 처리 개수\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        #assert 문이 False이면 assert 에러 발생\n",
    "        #assert는 에러문이 발생하지만, 코드가 중단되지는 않는다.\n",
    "        #즉 단어 벡터 크기가 병렬 처리 개수로 나누었을 때,\n",
    "        #맞아 떨어져야 잘 작동한 다는 뜻이다.\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        #하나의 head가 가지는 벡터 크기\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(\n",
    "            #shape(batch_size, MAX_LENGTH, num_heads, depth)\n",
    "            #=(64, 40, 8, 64)\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth)\n",
    "        )\n",
    "        #shape(batch_size, num_heads, MAX_LENGTH, depth)\n",
    "        #=(64, 8, 40, 64)\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # Q, K, V에 각각 Dense를 적용합니다\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        \n",
    "        # 병렬 연산을 위한 머리를 여러 개 만듭니다+++++++++++\n",
    "        #num_head 수 만큼 나누기\n",
    "        #shape(batch_size, num_heads, MAX_LENGTH, depth)\n",
    "        #=(64, 8, 40, 64)\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "        #End+++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "        \n",
    "\n",
    "        # 스케일드 닷 프로덕트 어텐션 함수\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "        #shape(batch_size, MAX_LENGTH, num_heads, depth)\n",
    "        #=(64, 40, 8, 64)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "        concat_attention = tf.reshape(\n",
    "            scaled_attention,\n",
    "            #shape(batch_size, MAX_LENGTH, (num_heads, depth))\n",
    "            #=(64, 40, 512)\n",
    "            (batch_size, -1, self.d_model)\n",
    "        )\n",
    "\n",
    "        # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-developer",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 4.3. 인코더 레이어\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 앞서 설명한 Multi Head Attention을 활용하여 인코더 레이어를 정의할 수 있습니다. 결국 Multi Head Attention은 설정한 Head의 수만큼 단어 간의 연관도를 계산하는 것입니다. 또한 입력과 출력의 크기가 동일하다는 것도 설명하였습니다. 입력과 출력의 크기가 동일하기 때문에 인코더 레이어를 여러 층 쌓는 것이 가능합니다.\n",
    "</span><br><br>\n",
    "\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 인코더 레이어의 형태는 앞서 설명한 Multi Head Attention 후에 Position-wise 피드 포워드 층이 오는데 피드 포워드 층은 흔히 알고 있는 Dense 층으로 이해할 수 있습니다. [그림 7]은 인코더 레이어의 아키텍처를 제시한 것입니다.\n",
    "</span>\n",
    "\n",
    "<img src=\"./img/encoder.png\" width=500>\n",
    "\n",
    "[그림 7] 인코더 레이어의 아키텍처\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "according-dictionary",
   "metadata": {},
   "source": [
    "#### 인코더 레이어 정의\n",
    "***\n",
    "+ 인코더 레이어를 정의합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "varying-election",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention\")({\n",
    "            'query': inputs,\n",
    "            'key': inputs,\n",
    "            'value': inputs,\n",
    "            'mask': padding_mask\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alone-kenya",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 4.4. 인코더 통합\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 이제 트랜스포머의 인코더 파트를 정의할 수 있습니다. 전체적으로 다시 설명하겠습니다. [그림 8]은 트랜스포머의 인코더 파트를 제시한 것입니다. 트랜스포머의 입력은 단어를 묶어 한번에 입력(Input) 합니다. 단어를 묶는다는 것은 결국 '문장을 한 번에 넣는다'라고 이해할 수 있습니다. 이는 임베딩 레이어를 통과하여 임베딩 벡터의 묶음, 행렬로 변환 됩니다. 단어의 순서를 적용하기 위해 Positional 인코딩을 추가하여 줍니다. Multi Head Attention에 입력하여 줍니다. 단어의 연관도를 구할 때, Padding의 연관도는 불필요하므로 padding mask도 함께 입력하여줍니다. 인코더 레이어는 여러 개를 쌓을 수 있으며, 논문에서는 6개의 인코더 레이어를 사용하였습니다. 최종 출력은 이후 디코더에 입력됩니다.\n",
    "</span><br><br>\n",
    "\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 트랜스포머 인코더 파트의 중요한 부분은 역시 Multi Head Attention이 사용되는 인코더 레이어일 것입니다. 입력되는 문장의 단어 간의 연관도를 구한다는 것. 그리고 인코더 파트의 Attention은 입력되는 하나의 문장에서 사용된 단어 간의 연관도를 구합니다. 따라서 'Self-Attention' 이라고 불리는 것입니다.\n",
    "</span>\n",
    "\n",
    "<img src=\"./img/encoder_arch.png\" width=500>\n",
    "\n",
    "[그림 8] 트랜스포머의 인코더\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-freedom",
   "metadata": {},
   "source": [
    "#### 인코더 통합하기\n",
    "***\n",
    "+ 앞서 정의한 레이어를 통합하여 트랜스포머의 인코더 파트를 정의 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "computational-trinidad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(\n",
    "    vocab_size,\n",
    "    num_layers,\n",
    "    units,\n",
    "    d_model,\n",
    "    num_heads,\n",
    "    dropout,\n",
    "    name=\"encoder\"\n",
    "):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # num_layers만큼 쌓아올린 인코더의 층.\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name=\"encoder_layer_{}\".format(i),\n",
    "        )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "    inputs=[inputs, padding_mask], outputs=outputs, name=name\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limited-appointment",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 4.4. 인코더와 디코더 연결 부분\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 앞서, 트랜스포머의 인코더를 설명하였습니다. 이번에는 인코더의 출력이 어떻게 활용되는지 설명하겠습니다. [그림 9]는 트랜스포머의 인코더와 디코더를 간략화한 것입니다. 결론만 말하자면 인코더의 최종 출력 중 Key와 Value가 디코더의 Multi Head Attention에 입력 됩니다. 이것이 의미하는 것은, 디코더에 입력된 단어 벡터들(Query)과 인코더로부터 입력된 단어 벡터들(Key, Value)의 연관도를 구한다는 것입니다. 'seq2seq'에 대입하여 설명하자면, 인코더로부터 입력되는 정보(Key, Value)는, 인코더의 정보가 함축된 Context vector에 해당한다고 할 수 있습니다.\n",
    "</span><br><br>\n",
    "\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 또한, 앞서 설명한 인코더의 Multi Head Attention은 입력된 하나의 문장 내의 단어 간 연관도를 구하였지만, 해당 Attention은 인코더에 입력된 단어들과 디코더에 입력된 단어들을 비교하는 것입니다. 그렇기 때문에 Self가 붙지않는 것을 확인할 수 있습니다.\n",
    "</span>\n",
    "\n",
    "<img src=\"./img/connect_enc_dec.png\" width=500>\n",
    "\n",
    "[그림 9] 트랜스포머의 인코더와 디코더\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-usage",
   "metadata": {},
   "source": [
    "### 4.5. Multi Head Attention\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 디코더의 Multi Head Attention에 대해 조금 더 하겠습니다. [그림 10]은 디코더의 Multi Head Attention 연산을 간략화 한 것입니다. 앞서 배운 것과 마찬가지로 softmax, 정규화 과정 모두 동일하지만 설명을 위해 Query, Key, Value 행렬만 시각화 하였습니다. 예제의 목표는 챗봇 이기 때문에 'I love you'라는 문장을 넣으면 'Me too'라는 문장을 출력하도록 학습한다고 가정해 보겠습니다.\n",
    "</span><br><br>\n",
    "\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 인코더에 'I love you'입력하였습니다. 이에 대한 Key, Value가 디코더로 넘어옵니다. 우리가 원하는 것은 이에 대해 'Me too'라고 대답하는 것입니다. 따라서 'I love you'와 '&lt;SOS> Me too'의 연관도를 구합니다. 즉, 한 문장 내의 단어 간 연관도를 구한 것이 아니라 다른 문장의 단어와의 연관도를 구하는 것입니다.\n",
    "</span>\n",
    "\n",
    "<img src=\"./img/dec2layer.png\" width=500>\n",
    "\n",
    "[그림 10] 디코더의 Multi Head Attention 연산\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-latitude",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 4.6. Look Ahead Mask\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 트랜스포머 디코더의 학습은 '교사강요'로 인해 target 문장이 그대로 들어갑니다. 이에따라 한 가지 문제가 발생합니다. [그림 11]은 학습 시 디코더에 입력되는 target 문장을 보여줍니다. 'I love you'라고 대답하도록 학습 시키기위해 해당 문장을 디코더에 입력합니다. 우리가 원하는 것은 모델이 I를 바탕으로 love를 예측하고 다음 'I love'를 바탕으로 You를 예측하는 것입니다. 하지만 문장이 그대로 입력되었기 때문에 답을 보고 대답하는 것과 마찬가지 입니다. 따라서, 이를 방지하기 위해 현재 시점 이후의 단어를 가려줄 필요가 있습니다. 그리고 이를 위한 기법이 바로 Look Ahead Mask 입니다.\n",
    "</span>\n",
    "\n",
    "<img src=\"./img/why_lock.png\" width=500>\n",
    "\n",
    "[그림 11] 학습 시 동시에 입력되는 데이터\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-ultimate",
   "metadata": {},
   "source": [
    "#### Look Ahead Mask 정의\n",
    "***\n",
    "+ Look Ahead Mask 정의하여 줍니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "thick-customs",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-copying",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 4.7. 디코더 레이어\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 디코더 레이어를 정의합니다. [그림 12]는 디코더 레이어의 아키텍처를 시각화 한 것입니다. 디코더 레이어의 특징은 Atetnion이 두 번 사용된다는 것입니다. 이를 간단히 설명하자면, 먼저 디코더에 입력되는 문장 내의 단어 간 연관도를 구하는 'Self Attention'을 수행하고 이를 바탕으로 질문에 대한 문장과 디코더 즉, 대답에 대한 문장 단어 간의 연관도를 구하는 Attention을 수행하는 것입니다. 충분히 논리적인 구성이라 생각됩니다. 이후 인코더 레이어와 마찬가지로 FFNN이 오게 됩니다.\n",
    "</span>\n",
    "\n",
    "<img src=\"./img/decoder.png\" width=600>\n",
    "\n",
    "[그림 12] 디코더 레이어 아키텍처\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-hurricane",
   "metadata": {},
   "source": [
    "#### 디코더 레이어 정의\n",
    "***\n",
    "+ 디코더 레이어를 정의 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "formal-breakdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name=\"look_ahead_mask\"\n",
    "    )\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "            'query': inputs,\n",
    "            'key': inputs,\n",
    "            'value': inputs,\n",
    "            'mask': look_ahead_mask\n",
    "        })\n",
    "\n",
    "    # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention1 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6\n",
    "    )(attention1 + inputs)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "            'query': attention1,\n",
    "            'key': enc_outputs,\n",
    "            'value': enc_outputs,\n",
    "            'mask': padding_mask\n",
    "        })\n",
    "\n",
    "    # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "    # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6\n",
    "    )(attention2 + attention1)\n",
    "\n",
    "    # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6\n",
    "    )(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-metabolism",
   "metadata": {},
   "source": [
    "#### 디코더 정의하기\n",
    "***\n",
    "+ 앞서 정의한 레이어를 이용하여 트랜스포머의 디코더를 정의 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "packed-lecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(\n",
    "    vocab_size,\n",
    "    num_layers,\n",
    "    units,\n",
    "    d_model,\n",
    "    num_heads,\n",
    "    dropout,\n",
    "    name='decoder'\n",
    "):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name='look_ahead_mask'\n",
    "    )\n",
    "\n",
    "    # 패딩 마스크\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-gibson",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 4.9. Transformer 정의\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 앞에서 정의한 트랜스포머의 인코더와 디코더를 통합하여 최종적으로 트랜스포머 모델을 정의합니다. [그림 13]은 트랜스포머 모델을 시각화 한 것입니다. 디코더에서는 최종적으로 단어사전 크기의 레이어를 통과한 후 softmax를 통해 단어의 확률분포를 출력합니다. 인코더와 디코더를 확인할 수 있고 앞에서 설명한 인코더와 디코더의 연결 형태, Look Ahead Mask 등을 확인할 수 있습니다. 인코더와 디코더는 총 2개를 이용하였으며, 임베딩 크기는 256, Head의 수는 8로 설정하였습니다.\n",
    "</span><br><br>\n",
    "\n",
    "<img src=\"./img/transformer_arch.png\" height=650>\n",
    "\n",
    "[그림 13] 트랜스포머 아키텍처\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-scottish",
   "metadata": {},
   "source": [
    "#### 인코더 디코더 통합하기\n",
    "***\n",
    "+ 인코더와 디코더를 통합하여 트랜스포머 모델을 정의합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "warming-funds",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(\n",
    "    vocab_size,\n",
    "    num_layers,\n",
    "    units,\n",
    "    d_model,\n",
    "    num_heads,\n",
    "    dropout,\n",
    "    name=\"transformer\"\n",
    "):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # 인코더에서 패딩을 위한 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None), name='enc_padding_mask'\n",
    "    )(inputs)\n",
    "\n",
    "    # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "    # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask,\n",
    "        output_shape=(1, None, None), name='look_ahead_mask'\n",
    "    )(dec_inputs)\n",
    "\n",
    "    # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "    # 디코더에서 패딩을 위한 마스크\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None), name='dec_padding_mask'\n",
    "    )(inputs)\n",
    "\n",
    "    # 인코더\n",
    "    enc_outputs = encoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "    # 디코더\n",
    "    dec_outputs = decoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-sister",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 모델 생성하기\n",
    "***\n",
    "+ 최종적으로 모델을 생성합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "unique-google",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    3139840     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    3667200     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8147)   2093779     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8,900,819\n",
      "Trainable params: 8,900,819\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-nickel",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 5. 모델 학습 및 평가\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; input_text\n",
    "</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-waters",
   "metadata": {},
   "source": [
    "### 5.1. 모델 학습\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 생성한 트랜스포머 모델을 학습하기위해 '손실함수 정의', '학습률 정의', '컴파일 정의' 과정을 수행 합니다. 손실함수는 패딩을 고려하여 마스크를 추가해주어 함수를 정의 합니다. 학습률은 고정하지 않고 학습 진행에 따라 변경되도록 합니다. 옵티마이저는 Adam을 이용하여 총 25epoch 학습을 진행합니다.\n",
    "</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-african",
   "metadata": {},
   "source": [
    "#### 손실함수 정의하기\n",
    "***\n",
    "+ 패딩을 제외한 단어에 대한 손실함수를 정의 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "unlike-omaha",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none'\n",
    "    )(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    #패딩이 아닌 단어만 살리기\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reasonable-backing",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 학습률 정의하기\n",
    "***\n",
    "+ 학습 진행 시에 학습률을 동일하게 적용하지 않고 진행 정도에 따라 학습률을 변경 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "closed-brush",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "    \n",
    "    \n",
    "#시각화=====================\n",
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")\n",
    "#End========================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-consent",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 컴파일 정의하기\n",
    "***\n",
    "+ 옵티마이저는 Adam을 이용하고 앞서 정의한 손실함수를 사용합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "exempt-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9\n",
    ")\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-malpractice",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 모델 학습하기\n",
    "***\n",
    "+ Epoch를 25로 설정하고 학습을 진행합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cultural-visiting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "142/142 [==============================] - 16s 63ms/step - loss: 5.8243 - accuracy: 0.0443\n",
      "Epoch 2/25\n",
      "142/142 [==============================] - 9s 62ms/step - loss: 4.9009 - accuracy: 0.2075\n",
      "Epoch 3/25\n",
      "142/142 [==============================] - 9s 62ms/step - loss: 4.0714 - accuracy: 0.2147\n",
      "Epoch 4/25\n",
      "142/142 [==============================] - 9s 62ms/step - loss: 3.5545 - accuracy: 0.2172\n",
      "Epoch 5/25\n",
      "142/142 [==============================] - 9s 61ms/step - loss: 3.3298 - accuracy: 0.2280\n",
      "Epoch 6/25\n",
      "142/142 [==============================] - 9s 61ms/step - loss: 3.1248 - accuracy: 0.2393\n",
      "Epoch 7/25\n",
      "142/142 [==============================] - 9s 62ms/step - loss: 2.9396 - accuracy: 0.2532\n",
      "Epoch 8/25\n",
      "142/142 [==============================] - 9s 62ms/step - loss: 2.7122 - accuracy: 0.2743\n",
      "Epoch 9/25\n",
      "142/142 [==============================] - 9s 61ms/step - loss: 2.4850 - accuracy: 0.3050\n",
      "Epoch 10/25\n",
      "142/142 [==============================] - 9s 62ms/step - loss: 2.2163 - accuracy: 0.3364\n",
      "Epoch 11/25\n",
      "142/142 [==============================] - 9s 62ms/step - loss: 1.9569 - accuracy: 0.3687\n",
      "Epoch 12/25\n",
      "142/142 [==============================] - 9s 61ms/step - loss: 1.6504 - accuracy: 0.4059\n",
      "Epoch 13/25\n",
      "142/142 [==============================] - 9s 61ms/step - loss: 1.3707 - accuracy: 0.4459\n",
      "Epoch 14/25\n",
      "142/142 [==============================] - 9s 61ms/step - loss: 1.0978 - accuracy: 0.4837\n",
      "Epoch 15/25\n",
      "142/142 [==============================] - 9s 61ms/step - loss: 0.8523 - accuracy: 0.5225\n",
      "Epoch 16/25\n",
      "142/142 [==============================] - 10s 70ms/step - loss: 0.6352 - accuracy: 0.5564\n",
      "Epoch 17/25\n",
      "142/142 [==============================] - 9s 61ms/step - loss: 0.4592 - accuracy: 0.5926\n",
      "Epoch 18/25\n",
      "142/142 [==============================] - 9s 61ms/step - loss: 0.3246 - accuracy: 0.6136\n",
      "Epoch 19/25\n",
      "142/142 [==============================] - 9s 62ms/step - loss: 0.2233 - accuracy: 0.6295\n",
      "Epoch 20/25\n",
      "142/142 [==============================] - 9s 61ms/step - loss: 0.1552 - accuracy: 0.6417\n",
      "Epoch 21/25\n",
      "142/142 [==============================] - 9s 61ms/step - loss: 0.1196 - accuracy: 0.6444\n",
      "Epoch 22/25\n",
      "142/142 [==============================] - 9s 61ms/step - loss: 0.1031 - accuracy: 0.6449\n",
      "Epoch 23/25\n",
      "142/142 [==============================] - 9s 61ms/step - loss: 0.0912 - accuracy: 0.6456\n",
      "Epoch 24/25\n",
      "142/142 [==============================] - 9s 61ms/step - loss: 0.0824 - accuracy: 0.6474\n",
      "Epoch 25/25\n",
      "142/142 [==============================] - 9s 61ms/step - loss: 0.0790 - accuracy: 0.6490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbe571c0790>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 25\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-gibson",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 5.1. 모델 평가\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 학습한 트랜스포머 모델의 문장 생성 능력을 확인합니다. [그림 14]는 트랜스포머의 입력에 대한 문장 생성 과정을 제시한 것입니다. '너 누구야?'라는 문장과 '&lt;SOS>'를 인코더와 디코더에 입력하면 단어 사전의 확률분포를 출력하고 그 중 높은 단어 채택합니다. [그림 14]에서는 '나'가 출력되었습니다. 그럼 '&lt;SOS>'와 '나'를 합친 후, 다시 '너 누구야?'라는 문장과 '&lt;SOS> 나'를 인코더와 디코더에 입력합니다. 그러한 과정을 설정한 문장의 최대 길이 만큼 수행하거나 종료 토큰이 출력될 때까지 반복 합니다.\n",
    "</span><br><br>\n",
    "\n",
    "<img src=\"./img/how_predict.png\" width=400>\n",
    "\n",
    "[그림 14] 트랜스포머의 문장생성 과정\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-companion",
   "metadata": {},
   "source": [
    "#### 문장 생성 과정 함수 생성\n",
    "***\n",
    "+ 모델에 문장을 입력하였을 때, 문장을 생성하는 과정을 함수로 생성합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "speaking-demonstration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "    sentence = preprocess_sentence(sentence)   #정규식을 이용한 전처리\n",
    "\n",
    "    # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "    sentence = tf.expand_dims(\n",
    "        START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0\n",
    "    )\n",
    "\n",
    "    # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "    # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "    output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "    # 디코더의 인퍼런스 단계\n",
    "    for i in range(MAX_LENGTH):\n",
    "        # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "        predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "        predictions = predictions[:, -1:, :]\n",
    "\n",
    "        # 현재 예측한 단어의 정수\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "            break\n",
    "\n",
    "        # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "        # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "        output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-overview",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 정수 문장을 자연어 문장으로 변환하는 함수 생성\n",
    "***\n",
    "+ 모델이 출력한 정수로된 문장을 자연어 문장으로 변환하는 함수를 생성합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "diagnostic-transparency",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "    # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "    prediction = decoder_inference(sentence)\n",
    "\n",
    "    # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "        [i for i in prediction if i < tokenizer.vocab_size]\n",
    "    )\n",
    "\n",
    "    print('입력 : {}'.format(sentence))\n",
    "    return ('출력 : {}'.format(predicted_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-frederick",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 문장 생성 확인하기\n",
    "***\n",
    "+ 모델의 문장 생성 능력을 확인한다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "marked-conclusion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "입력 : 밥 먹었니?\n",
      "출력 : 배고프지 않아요 .\n",
      "\n",
      "입력 : 너 누구야?\n",
      "출력 : 저는 마음을 이어주는 위로봇입니다 .\n",
      "\n",
      "입력 : 안녕~\n",
      "출력 : 안녕하세요 .\n",
      "\n",
      "입력 : 여행가자\n",
      "출력 : 계획을 세워보세요 .\n",
      "\n",
      "입력 : 사랑이 뭐야?\n",
      "출력 : 신뢰이자 믿음이라고 생각해요 .\n",
      "\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "print(\"*\" * 50)\n",
    "print(sentence_generation('밥 먹었니?'), end=\"\\n\\n\")\n",
    "print(sentence_generation('너 누구야?'), end=\"\\n\\n\")\n",
    "print(sentence_generation('안녕~'), end=\"\\n\\n\")\n",
    "print(sentence_generation('여행가자'), end=\"\\n\\n\")\n",
    "print(sentence_generation('사랑이 뭐야?'), end=\"\\n\\n\")\n",
    "print(\"*\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-picnic",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 6. 결론\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 본 예제에서는 트랜스포머 챗봇 모델을 생성, 학습하고 모델의 문장생성 능력을 확인하였습니다. 한국어 문장 데이터를 이용하였으며, 8,147개의 단어와 9,084개의 문장을 바탕으로 모델을 학습하였습니다. 모델의 문장생성 능력을 확인하기 위해 '밥 먹었니?', '너 누구야?', '안녕~' 등의 문장을 입력한 결과, '배고프지 않아요.', '저는 마음을 이어주는 위로봇입니다.', '안녕하세요.' 등 상당히 자연스러운 문장을 생성하였습니다. 다음은 입력한 문장과 그에 대한 모델이 생성한 문장을 제시한 것입니다.\n",
    "</span><br><br>\n",
    "\n",
    "\n",
    "> ___Q: 밥 먹었니?___\n",
    ">\n",
    "> ___A: 배고프지 않아요.___\n",
    "\n",
    "\n",
    "> ___Q: 너 누구야?___\n",
    ">\n",
    "> ___A: 저는 마음을 이어주는 위로봇입니다.___\n",
    "\n",
    "\n",
    "> ___Q: 안녕~___\n",
    ">\n",
    "> ___A: 안녕하세요.___\n",
    "\n",
    "\n",
    "> ___Q: 여행가자___\n",
    ">\n",
    "> ___A: 계획을 세워보세요.___\n",
    "\n",
    "\n",
    "> ___Q: 사랑이 뭐야?___\n",
    ">\n",
    "> ___A: 신뢰이자 믿음이라고 생각해요.___\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-prior",
   "metadata": {},
   "source": [
    "#### 형상관리 기록\n",
    "***\n",
    "+ v1_1: 초기모델\n",
    "\n",
    "\n",
    "+ v1_2: 제출 예제 진행\n",
    "\n",
    "\n",
    "+ v2_1: 코드 단위 분석\n",
    "\n",
    "\n",
    "+ v3_1: 문장 길이 분석\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
